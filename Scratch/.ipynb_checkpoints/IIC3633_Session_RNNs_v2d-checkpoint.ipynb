{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhMT2zYloMpm"
   },
   "source": [
    "#**Proyecto - Sistemas Recomendadores - IIC3633**\n",
    "\n",
    "## Implementación en Keras de Session-Based RNNs for Recommendation con soft atenttion\n",
    "\n",
    "### V1: modelo con embedding, GRU de 1000, densa sobre one-hot encoding de items\n",
    "\n",
    "\n",
    "Preliminar: Configuración entorno GPUs, Google Drive, entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "Z5dA3-L0nfLG",
    "outputId": "ace05f26-42f3-41a7-8911-f93c2709d85c"
   },
   "outputs": [],
   "source": [
    "# Manejo de Google Drive\n",
    "!pip install -U -q PyDrive\n",
    "\n",
    "from google.colab import drive, auth\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "drive.mount(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "6LGXgPsyoWsr",
    "outputId": "8a0b95ca-b0fc-44ba-8f55-e57a36e72c3e"
   },
   "outputs": [],
   "source": [
    "# Librerias varias\n",
    "\n",
    "!pip install gputil\n",
    "!pip install humanize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3kJRW-qQ17_Q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import psutil\n",
    "import humanize\n",
    "import GPUtil as GPU\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import cosine_proximity, categorical_crossentropy\n",
    "from keras.models import Model, Sequential\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Input, Dense, Dropout, CuDNNGRU, Embedding, concatenate, Lambda, multiply\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "ik4GlGz8oZvj",
    "outputId": "177b90ae-a085-45ce-edd8-8769eb672211"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 12.8 GB  I Proc size: 236.6 MB\n",
      "GPU RAM Free 7686MB | Used: 419MB | Util   5% | Total          8105MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('/device:GPU:0',\n",
       "  <google.protobuf.pyext._message.MessageDescriptor at 0x7f43b48646d0>,\n",
       "  2,\n",
       "  1,\n",
       "  7)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuracion GPUs\n",
    "#!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "\n",
    "GPUs = GPU.getGPUs()\n",
    "gpu = GPUs[0]\n",
    "\n",
    "def print_gpu_info():\n",
    "  process = psutil.Process(os.getpid())\n",
    "  print(\"Gen RAM Free: \" + humanize.naturalsize(\n",
    "          psutil.virtual_memory().available), \" I Proc size: \"  +\n",
    "          humanize.naturalsize(process.memory_info().rss))\n",
    "  print(\"GPU RAM Free {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total \\\n",
    "         {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, \n",
    "                           gpu.memoryTotal))\n",
    "  \n",
    "print_gpu_info()\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [(x.name, x.DESCRIPTOR, x.DEVICE_TYPE_FIELD_NUMBER, x.NAME_FIELD_NUMBER, x.PHYSICAL_DEVICE_DESC_FIELD_NUMBER) for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfW00EfwSNQ6"
   },
   "outputs": [],
   "source": [
    "# Cargamos dataframes preprocesados de RSC15\n",
    "PATH_TO_TRAIN = '../processedData/rsc15_train_tr.txt'\n",
    "PATH_TO_DEV = '../processedData/rsc15_train_valid.txt'\n",
    "PATH_TO_TEST = '../processedData/rsc15_test.txt'\n",
    "\n",
    "train_data = pd.read_csv(PATH_TO_TRAIN, sep='\\t', dtype={'ItemId':np.int64})\n",
    "dev_data = pd.read_csv(PATH_TO_DEV, sep='\\t', dtype={'ItemId':np.int64})\n",
    "test_data = pd.read_csv(PATH_TO_TEST, sep='\\t', dtype={'ItemId': np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFkivhjnvrKO"
   },
   "outputs": [],
   "source": [
    "def batch_generator(data, batch_size=128, session_max_len=19, fraction=1, offset=0, embedding=True, n_items=None, itemids=None, itemidmap=None):\n",
    "    \"\"\"\n",
    "    Generador de batches para RSC15.\n",
    "    Se utiliza para entrenar, validar y testear en demanda.\n",
    "        args:\n",
    "            data: DataFrame pandas con info. a procesar\n",
    "            batch_size: tamanho batch\n",
    "            session_max_len: largo fijo para sesiones. De ser mayor, se trunca. De ser menor, left-zero-padding\n",
    "            fraction: fraccion mas reciente de sesiones que se consideran para la generacion\n",
    "            offset: parametro que permite salto manual de sesiones\n",
    "            embedding: Booleano que indica si el modelo actual predice embeddings, o one-hot encodings\n",
    "            n_items: cantidad de items unicos a predecir\n",
    "            itemids: lista con los IDs unicos de items en el set de datos a considerar\n",
    "            itemidmap: biyeccion de IDs en dataset a rango simple (0, n_items)\n",
    "    \"\"\"\n",
    "    \n",
    "    item_key = 'ItemId'\n",
    "    session_key = 'SessionId'\n",
    "    time_key = 'Time'\n",
    "    \n",
    "    # inner join dataframe con itemidmap\n",
    "    data = pd.merge(data, pd.DataFrame({item_key:itemids, 'ItemIdx':itemidmap[itemids].values}), on=item_key, how='inner') # agrego esa columna\n",
    "    data.sort_values([session_key, time_key], inplace=True) # ordenamos por sesion\n",
    "\n",
    "    length = len(data['ItemId'])\n",
    "    #data.sort_values([time_key], inplace=True)\n",
    "    #data = data[length-length//fraction:]\n",
    "    \n",
    "    # arreglo con offset acumulativo de inicio de cada sesion\n",
    "    offset_sessions = np.zeros(data[session_key].nunique()+1, dtype=np.int32)\n",
    "    offset_sessions[1:] = data.groupby(session_key).size().cumsum() \n",
    "    #offset_sessions = offset_sessions[length-length//fraction:]\n",
    "    \n",
    "    actual_session = 0 + offset\n",
    "    batch_feats = None\n",
    "    batch_labels = None\n",
    "    \n",
    "    # K.reset_states(GRU_LAYER) si usamos session parallel approach\n",
    "\n",
    "    while True:\n",
    "        # la info de la sesion a considerar\n",
    "        datum = data[offset_sessions[actual_session]:offset_sessions[actual_session+1]][item_key]  \n",
    "        datum = datum.values.reshape(-1,1)\n",
    "        \n",
    "        # data augmentation\n",
    "        for i in range(offset_sessions[actual_session+1]-offset_sessions[actual_session]-1):\n",
    "            feats = datum[0:i+1]\n",
    "            \n",
    "            # truncate\n",
    "            if feats.shape[0] > session_max_len:\n",
    "                feats = feats[:session_max_len]\n",
    "            # zero padding\n",
    "            else:\n",
    "                feats = np.append(np.zeros((session_max_len-feats.shape[0],1), dtype=np.int8), feats) # left pad with zeros\n",
    "                      \n",
    "            feats = feats.reshape(1,-1) # (1, 19)        \n",
    "            label = datum[i+1]\n",
    "            label = np.expand_dims(label, axis=0)\n",
    "            \n",
    "            # add to batch\n",
    "            if not isinstance(batch_feats, type(feats)):\n",
    "                batch_feats = feats\n",
    "            else:\n",
    "                batch_feats = np.append(batch_feats, feats, axis=0)\n",
    "\n",
    "            if not isinstance(batch_labels, type(label)):\n",
    "                batch_labels = label\n",
    "            else:\n",
    "                batch_labels = np.append(batch_labels, label, axis=0)\n",
    "\n",
    "            # if batch is ready\n",
    "            if batch_labels.shape[0] == batch_size:\n",
    "                if not embedding:\n",
    "                    # do one hot if necessary\n",
    "                    batch_labels = to_categorical(itemidmap[batch_labels.flatten()], num_classes=n_items)\n",
    "                \n",
    "                # return batch\n",
    "                yield batch_feats, batch_labels\n",
    "                \n",
    "                # resume generation\n",
    "                batch_feats = None\n",
    "                batch_labels = None\n",
    "        \n",
    "        actual_session = (actual_session + 1) % len(offset_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "eQslL5CpRjdQ",
    "outputId": "6d2fc6bf-34f8-446b-91b2-34e605ba9974"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items unicos training: 37484\n",
      "Items unicos dev: 6360\n",
      "Items unicos testing: 6752\n",
      "Sesiones training: 7953885\n",
      "Sesiones validation: 12372\n",
      "Sesiones testing: 15324\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "session_max_len = 19\n",
    "embeddingp=False\n",
    "\n",
    "n_items = len(train_data['ItemId'].unique())+1\n",
    "print(\"Items unicos training:\", n_items)\n",
    "\n",
    "dev_n_items = len(dev_data['ItemId'].unique())+1\n",
    "print(\"Items unicos dev:\", dev_n_items)\n",
    "\n",
    "test_n_items = len(test_data['ItemId'].unique())+1\n",
    "print(\"Items unicos testing:\", test_n_items)\n",
    "\n",
    "train_samples_qty = len(train_data['SessionId'].unique()) # cantidad sesiones no augmentadas de train\n",
    "print(\"Sesiones training:\", train_samples_qty)\n",
    "\n",
    "dev_samples_qty = len(dev_data['SessionId'].unique()) # cantidad sesiones no augmentadas de dev\n",
    "print(\"Sesiones validation:\",dev_samples_qty)\n",
    "\n",
    "test_samples_qty = len(test_data['SessionId'].unique()) # cantidad sesiones no augmentadas de test\n",
    "print(\"Sesiones testing:\", test_samples_qty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "AdM3tjmSbxjG",
    "outputId": "a4279c1b-f3e3-474c-a8bf-9f2c24386c11",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 19)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 19, 50)            1874200   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 19, 50)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)       (None, 1000)              3156000   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 37484)             37521484  \n",
      "=================================================================\n",
      "Total params: 42,551,684\n",
      "Trainable params: 42,551,684\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcerdam/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "\n",
    "def custom_cosine_loss(model):\n",
    "    \"\"\"Funcion custom para el modelo con embedding, m4\"\"\"\n",
    "    emb = model.layers[1]\n",
    "    # y_pred: con embedding\n",
    "    # y_true: one-hot\n",
    "    def fn(y_true, y_pred):\n",
    "        y_true_emb = emb.call(y_true)\n",
    "        #y_true_emb = np.array([y_true], dtype='int32')\n",
    "        #y_true_emb = tf.convert_to_tensor(y_true_emb)\n",
    "        #y_true_emb = model.layers[0].call(y_true)\n",
    "        #y_true_emb = K.get_value(y_true_emb)[0][0] # 50,\n",
    "        return 1 - cosine_proximity(y_true_emb, y_pred)\n",
    "    return fn\n",
    "    \n",
    "emb_size = 50\n",
    "size = emb_size if embeddingp else n_items\n",
    "\n",
    "inputs = Input(shape=(19,))\n",
    "emb = Embedding(n_items, emb_size, embeddings_initializer='uniform', input_length=19)(inputs)\n",
    "drop1 = Dropout(0.25)(emb)\n",
    "gru = CuDNNGRU(1000)(drop1)\n",
    "drop2 = Dropout(0.25)(gru)\n",
    "predictions = Dense(size, activation='softmax')(drop2)\n",
    "model = Model(input=inputs, output=[predictions])\n",
    "#custom_loss = custom_cosine_loss(model)\n",
    "model.compile(loss=categorical_crossentropy, optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "filepath=\"model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=2, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1i_adI_ASgDi"
   },
   "outputs": [],
   "source": [
    "train_fraction = 1 # 1/fraction: cantidad sesiones mas recientes a considerar\n",
    "dev_fraction = 1\n",
    "\n",
    "train_offset_step=45000 #*batch_size = 23MM\n",
    "dev_offset_step=72      #*batch_size = 37k\n",
    "\n",
    "\n",
    "aux = [0]  # 0 es token especial\n",
    "aux.extend(list(train_data['ItemId'].unique()))\n",
    "itemids = np.array(aux)\n",
    "itemidmap = pd.Series(data=np.arange(n_items), index=itemids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "id": "7FvXrjm3Sg1F",
    "outputId": "ae324c56-f702-4eb4-a79c-f79442617a02",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 8882s 197ms/step - loss: 9.3847 - val_loss: 13.4051\n",
      "\n",
      "Epoch 00001: loss improved from inf to 9.38474, saving model to model.hdf5\n",
      "Epoch 1/1\n",
      "  295/45000 [..............................] - ETA: 4:15:56 - loss: 8.2129"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f590155a05d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                 \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_offset_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#105,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                 callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2242\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2243\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2244\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1888\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(1, 15):\n",
    "    train_generator = batch_generator(train_data, \n",
    "                                      batch_size=batch_size, \n",
    "                                      fraction=train_fraction, \n",
    "                                      offset=train_offset_step*epoch,\n",
    "                                      embedding=embeddingp,\n",
    "                                      n_items=n_items,\n",
    "                                      itemids=itemids,\n",
    "                                      itemidmap=itemidmap)\n",
    "    \n",
    "    dev_generator = batch_generator(dev_data, \n",
    "                                    batch_size=batch_size, \n",
    "                                    fraction=dev_fraction, \n",
    "                                    offset=dev_offset_step*epoch,\n",
    "                                    embedding=embeddingp,\n",
    "                                    n_items=n_items,\n",
    "                                    itemids=itemids,\n",
    "                                    itemidmap=itemidmap)\n",
    "    \n",
    "    history = model.fit_generator(  train_generator,\n",
    "                                    steps_per_epoch=train_offset_step,#15530,\n",
    "                                    epochs=1,\n",
    "                                    validation_data=dev_generator,\n",
    "                                    validation_steps=dev_offset_step,#105,\n",
    "                                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SL6iBzAvqJjF",
    "outputId": "8faaa34f-4323-4897-aaa1-cc8a0a2916e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.242373847961426"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test performance over test set\n",
    "\n",
    "test_generator = batch_generator(   test_data, \n",
    "                                    batch_size=batch_size, \n",
    "                                    fraction=train_fraction, \n",
    "                                    offset=0*epoch,\n",
    "                                    embedding=embeddingp,\n",
    "                                    n_items=n_items,\n",
    "                                    itemids=itemids,\n",
    "                                    itemidmap=itemidmap)\n",
    "\n",
    "model.evaluate_generator(   test_generator, \n",
    "                            steps=40, \n",
    "                            max_queue_size=10, \n",
    "                            workers=1, \n",
    "                            use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1476
    },
    "colab_type": "code",
    "id": "VNvk1oYaZIU1",
    "outputId": "86934cc8-3ae2-4583-e03d-2de17eada7f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.0010571961009174311\n"
     ]
    }
   ],
   "source": [
    "# Recall score\n",
    "\n",
    "test_generator = batch_generator(test_data, \n",
    "                                  batch_size=batch_size, \n",
    "                                  fraction=train_fraction, \n",
    "                                  offset=0,\n",
    "                                 embedding=embeddingp,\n",
    "                                  n_items=n_items,\n",
    "                                 itemids=itemids,\n",
    "                                 itemidmap=itemidmap)\n",
    "\n",
    "\n",
    "n = 0\n",
    "suma = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        test_batch = next(test_generator)\n",
    "        pred = model.predict(test_batch[0]) # batch_size, n_items => 512, 37484\n",
    "        label = test_batch[1]               \n",
    "\n",
    "        for row_idx in range(test_batch[0].shape[0]):\n",
    "            pred_row = pred[row_idx] # 37484, #.reshape(1, -1) # 50,\n",
    "            label_row = label[row_idx]        #.reshape(1, -1) # 50,\n",
    "\n",
    "            #print(pred_row.shape)\n",
    "            #print(label_row.shape)\n",
    "\n",
    "            idx1 = pred_row.argsort()[-20:][::-1]\n",
    "            idx2 = label_row.argsort()[-1:][::-1]\n",
    "\n",
    "            #print(idx1)\n",
    "            #print(idx2)\n",
    "            \n",
    "            n += 1\n",
    "            if idx2[0] in idx1:\n",
    "                suma += 1\n",
    "    except:\n",
    "        break\n",
    "        \n",
    "print(\"Recall: \", suma/n)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IIC3633 Session RNNs v2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
