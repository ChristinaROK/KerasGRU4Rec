{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhMT2zYloMpm"
   },
   "source": [
    "#**Proyecto - Sistemas Recomendadores - IIC3633**\n",
    "\n",
    "## Implementación en Keras de Session-Based RNNs for Recommendation con soft atenttion\n",
    "\n",
    "### V2: Implementación de embedding sobre one-hot vectors para entrenamiento más eficiente y modelo más chico\n",
    "\n",
    "\n",
    "Preliminar: Configuración entorno GPUs, Google Drive, entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Z5dA3-L0nfLG",
    "outputId": "3559034d-eebf-445a-cb0b-e38eec640156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Manejo de Google Drive\n",
    "from google.colab import drive\n",
    "\n",
    "!pip install -U -q PyDrive\n",
    "drive.mount(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "6LGXgPsyoWsr",
    "outputId": "b2da63a3-e576-4d19-c07a-59eaa72178da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil) (1.14.6)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "# Librerias varias\n",
    "\n",
    "!pip install gputil\n",
    "!pip install humanize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3kJRW-qQ17_Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import psutil\n",
    "import humanize\n",
    "import GPUtil as GPU\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "ik4GlGz8oZvj",
    "outputId": "67d71c20-0dc4-4322-988f-d33daf2dd602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: cannot remove '/usr/bin/nvidia-smi': Permission denied\n",
      "Gen RAM Free: 11.9 GB  I Proc size: 237.5 MB\n",
      "GPU RAM Free 7583MB | Used: 522MB | Util   6% | Total          8105MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('/device:GPU:0',\n",
       "  <google.protobuf.pyext._message.MessageDescriptor at 0x7fd7a05236b0>,\n",
       "  2,\n",
       "  1,\n",
       "  7)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuracion GPUs\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "\n",
    "GPUs = GPU.getGPUs()\n",
    "gpu = GPUs[0]\n",
    "\n",
    "def print_gpu_info():\n",
    "  process = psutil.Process(os.getpid())\n",
    "  print(\"Gen RAM Free: \" + humanize.naturalsize(\n",
    "          psutil.virtual_memory().available), \" I Proc size: \"  +\n",
    "          humanize.naturalsize(process.memory_info().rss))\n",
    "  print(\"GPU RAM Free {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total \\\n",
    "         {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, \n",
    "                           gpu.memoryTotal))\n",
    "  \n",
    "print_gpu_info()\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [(x.name, x.DESCRIPTOR, x.DEVICE_TYPE_FIELD_NUMBER, x.NAME_FIELD_NUMBER, x.PHYSICAL_DEVICE_DESC_FIELD_NUMBER) for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJtwaqa3oeWK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras\n",
    "\n",
    "import sys\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import SimpleRNN, Dense, Flatten, Dropout, TimeDistributed, LSTM\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfW00EfwSNQ6"
   },
   "outputs": [],
   "source": [
    "# Cargamos dataframes preprocesados de RSC15\n",
    "PATH_TO_TRAIN = '../processedData/rsc15_train_tr.txt'\n",
    "PATH_TO_DEV = '../processedData/rsc15_train_valid.txt'\n",
    "PATH_TO_TEST = '../processedData/rsc15_test.txt'\n",
    "\n",
    "train_data = pd.read_csv(PATH_TO_TRAIN, sep='\\t', dtype={'ItemId':np.int64})\n",
    "dev_data = pd.read_csv(PATH_TO_DEV, sep='\\t', dtype={'ItemId':np.int64})\n",
    "test_data = pd.read_csv(PATH_TO_TEST, sep='\\t', dtype={'ItemId': np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lvPqM-J5T3HW"
   },
   "outputs": [],
   "source": [
    "# Pruebas\n",
    "\n",
    "item_key = 'ItemId'\n",
    "session_key = 'SessionId'\n",
    "time_key = 'Time'\n",
    "\n",
    "itemids = data[item_key].unique()\n",
    "n_items = len(itemids)\n",
    "\n",
    "itemidmap = pd.Series(data=np.arange(n_items), index=itemids) # Mapeo desde los 37.5k a (0, 37.5k) id\n",
    "mdata = pd.merge(data, pd.DataFrame({item_key:itemids, 'ItemIdx':itemidmap[itemids].values}), on=item_key, how='inner') # agrego esa columna\n",
    "\n",
    "mdata.sort_values([session_key, time_key], inplace=True) # ordenamos por sesion\n",
    "offset_sessions = np.zeros(mdata[session_key].nunique()+1, dtype=np.int32)\n",
    "offset_sessions[1:] = mdata.groupby(session_key).size().cumsum() # arreglo con offset acumulativo de inicio de cada sesion\n",
    "actual_session = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "yDwZbzzgXl1Y",
    "outputId": "48f39937-e921-4aac-e8b1-64f21f8e8df6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SessionId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Time</th>\n",
       "      <th>ItemIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>214536502</td>\n",
       "      <td>1.396879e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>1</td>\n",
       "      <td>214536500</td>\n",
       "      <td>1.396879e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>1</td>\n",
       "      <td>214536506</td>\n",
       "      <td>1.396879e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>1</td>\n",
       "      <td>214577561</td>\n",
       "      <td>1.396879e+09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>2</td>\n",
       "      <td>214662742</td>\n",
       "      <td>1.396890e+09</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SessionId     ItemId          Time  ItemIdx\n",
       "0             1  214536502  1.396879e+09        0\n",
       "1770          1  214536500  1.396879e+09        1\n",
       "2312          1  214536506  1.396879e+09        2\n",
       "2381          1  214577561  1.396879e+09        3\n",
       "2519          2  214662742  1.396890e+09        4"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SpGRmKjhX-Kv",
    "outputId": "d7dcbd5e-5514-498c-a573-9bf3d4dafe59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    }
   ],
   "source": [
    "#list(mdata[mdata['ItemId']==214536500]['ItemIdx'])[0]\n",
    "#print(mdata[mdata['ItemId']==214652220]['ItemIdx'].unique()[0])\n",
    "print(mdata[mdata['ItemId']==214652220]['ItemIdx'].unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ryuCgz-q4BFq",
    "outputId": "211117b1-16b4-4d93-b4c3-9c5f3ed2ee4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 19, 37484)\n",
      "(128, 1, 37484)\n"
     ]
    }
   ],
   "source": [
    "# Pruebas\n",
    "\"\"\"\n",
    "actual_session = 0\n",
    "\n",
    "batch_size = 128\n",
    "batch_feats = None\n",
    "batch_labels = None\n",
    "\n",
    "# Entrega tensores de shape (batch_size, n_items+1, 19)\n",
    "\n",
    "while True:\n",
    "    datum = mdata[offset_sessions[actual_session]:offset_sessions[actual_session+1]][item_key]  # aqui toda la info de la sesion\n",
    "    datum = datum.values.reshape(-1,1)\n",
    "    \n",
    "    for i in range(offset_sessions[actual_session+1]-offset_sessions[actual_session]-1):\n",
    "        \n",
    "        feats = datum[0:i+1]\n",
    "        if feats.shape[0] > 19:\n",
    "            feats = feats[:19]\n",
    "        else:\n",
    "            feats = np.append(np.zeros((19-feats.shape[0],1), dtype=np.int8), feats) # left pad with zeros\n",
    "\n",
    "        encoded_feats = None\n",
    "        for elt in feats:\n",
    "            if elt == 0:\n",
    "                idx = n_items\n",
    "            else:\n",
    "                idx = mdata[mdata['ItemId']==elt]['ItemIdx'].unique()[0]\n",
    "            encoded = to_categorical(idx, num_classes=n_items+1)\n",
    "            encoded = encoded.reshape(1, -1)\n",
    "            \n",
    "            if not isinstance(encoded_feats, type(feats)):\n",
    "                encoded_feats = encoded\n",
    "            else:\n",
    "                encoded_feats = np.append(encoded_feats, encoded, axis=0) # Termina siendo de (19, n_items)\n",
    "                \n",
    "        label_idx = mdata[mdata['ItemId']==datum[i+1][0]]['ItemIdx'].unique()[0]\n",
    "        label = to_categorical(label_idx, num_classes=n_items+1)\n",
    "        label = np.expand_dims(label, axis=0)  # Termina siendo (1, n_items)\n",
    "\n",
    "        if not isinstance(batch_feats, type(feats)):\n",
    "            batch_feats = np.expand_dims(encoded_feats, axis=0)\n",
    "        else:\n",
    "            batch_feats = np.append(batch_feats, np.expand_dims(encoded_feats, axis=0), axis=0)\n",
    "\n",
    "        if not isinstance(batch_labels, type(label)):\n",
    "            batch_labels = np.expand_dims(label, axis=0)\n",
    "        else:\n",
    "            batch_labels = np.append(batch_labels, np.expand_dims(label, axis=0), axis=0)\n",
    "\n",
    "        if batch_labels.shape[0] == batch_size:\n",
    "            print(batch_feats.shape)\n",
    "            print(batch_labels.shape)\n",
    "            break\n",
    "    \n",
    "    if batch_labels.shape[0] == batch_size:\n",
    "        break\n",
    "        \n",
    "    actual_session += 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFkivhjnvrKO"
   },
   "outputs": [],
   "source": [
    "def batch_generator(data, batch_size=128, session_max_len=19):\n",
    "    item_key = 'ItemId'\n",
    "    session_key = 'SessionId'\n",
    "    time_key = 'Time'\n",
    "    \n",
    "    itemids = data[item_key].unique()\n",
    "    n_items = len(itemids)\n",
    "    \n",
    "    itemidmap = pd.Series(data=np.arange(n_items), index=itemids) # Mapeo desde los 37.5k a (0, 37.5k) id\n",
    "    data = pd.merge(data, pd.DataFrame({item_key:itemids, 'ItemIdx':itemidmap[itemids].values}), on=item_key, how='inner') # agrego esa columna\n",
    "\n",
    "    data.sort_values([session_key, time_key], inplace=True) # ordenamos por sesion\n",
    "    offset_sessions = np.zeros(data[session_key].nunique()+1, dtype=np.int32)\n",
    "    offset_sessions[1:] = data.groupby(session_key).size().cumsum() # arreglo con offset acumulativo de inicio de cada sesion\n",
    "    actual_session = 0\n",
    "    \n",
    "    batch_feats = None\n",
    "    batch_labels = None\n",
    "\n",
    "    while True:\n",
    "        datum = data[offset_sessions[actual_session]:offset_sessions[actual_session+1]][item_key]  # aqui toda la info de la sesion\n",
    "        datum = datum.values.reshape(-1,1)\n",
    "        \n",
    "        for i in range(offset_sessions[actual_session+1]-offset_sessions[actual_session]-1):\n",
    "            feats = datum[0:i+1]\n",
    "            if feats.shape[0] > session_max_len:\n",
    "                feats = feats[:session_max_len]\n",
    "            else:\n",
    "                feats = np.append(np.zeros((session_max_len-feats.shape[0],1), dtype=np.int8), feats) # left pad with zeros\n",
    "            \n",
    "            feats = feats.reshape(1,-1)\n",
    "\n",
    "            label = np.array([data[data['ItemId']==datum[i+1][0]]['ItemIdx'].unique()[0]])\n",
    "            label = np.expand_dims(label, axis=0)  # Termina siendo (1, n_items)\n",
    "            \n",
    "            if not isinstance(batch_feats, type(feats)):\n",
    "                batch_feats = feats\n",
    "            else:\n",
    "                batch_feats = np.append(batch_feats, feats, axis=0)\n",
    "\n",
    "            if not isinstance(batch_labels, type(label)):\n",
    "                batch_labels = label #np.expand_dims(label, axis=0)\n",
    "            else:\n",
    "                batch_labels = np.append(batch_labels, label, axis=0)#np.expand_dims(label, axis=0), axis=0)\n",
    "\n",
    "            if batch_labels.shape[0] == batch_size:\n",
    "                # print(\"Yielding batch with shape {} train, {} target\".format(batch_feats.shape, batch_labels.shape))\n",
    "                yield batch_feats, batch_labels\n",
    "                \n",
    "                # resume batch generation\n",
    "                batch_feats = None\n",
    "                batch_labels = None\n",
    "            \n",
    "        # TODO: Dropout random como en el paper\n",
    "        \n",
    "        actual_session = (actual_session + 1) % len(offset_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eQslL5CpRjdQ",
    "outputId": "c30f728d-d224-4722-d4de-31923f96f995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37484\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128 # 512 en el paper\n",
    "session_max_len = 19\n",
    "n_items = len(train_data['ItemId'].unique())+1\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "AdM3tjmSbxjG",
    "outputId": "ee934819-9c94-440d-b9c2-521df6987a84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 19, 50)            1874200   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 19, 50)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 100)               45600     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "=================================================================\n",
      "Total params: 1,924,850\n",
      "Trainable params: 1,924,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "\n",
    "# ToDo:\n",
    "# meterle self-attention (hay implementaciones en Keras)\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.losses import cosine_proximity\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, Dense, Dropout, CuDNNGRU, GRU, Embedding, Flatten, Input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def custom_cosine_loss(emb):\n",
    "    # y_pred ya viene con embedding, y_true solo como one-hot\n",
    "    def fn(y_true, y_pred):\n",
    "        y_true_emb = emb.call(y_true)\n",
    "        return 1 - cosine_proximity(y_true_emb, y_pred)\n",
    "    return fn\n",
    "    \n",
    "\n",
    "model = Sequential()\n",
    "emb = Embedding(n_items, 50, input_length=19)\n",
    "model.add(emb)\n",
    "model.add(Dropout(0.25))\n",
    "model.add(CuDNNGRU(100)) # Probar con 1000, eventualmente \n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "#model.add(Dropout(0.2)) # Probar esto mas adelante\n",
    "custom_loss = custom_cosine_loss(emb)\n",
    "model.compile(loss=custom_loss, optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "filepath=\"model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=2, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1i_adI_ASgDi"
   },
   "outputs": [],
   "source": [
    "train_generator = batch_generator(train_data, batch_size=batch_size)\n",
    "\n",
    "dev_generator = batch_generator(dev_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1589
    },
    "colab_type": "code",
    "id": "7FvXrjm3Sg1F",
    "outputId": "92a3170d-ddd3-432d-aff3-97db002afb25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "500/500 [==============================] - 1726s 3s/step - loss: 0.0187 - val_loss: 0.0562\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.01869, saving model to model.hdf5\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 1679s 3s/step - loss: 0.0136 - val_loss: 0.0560\n",
      "\n",
      "Epoch 00001: loss improved from 0.01869 to 0.01358, saving model to model.hdf5\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 1782s 4s/step - loss: 0.0117 - val_loss: 0.0497\n",
      "\n",
      "Epoch 00001: loss improved from 0.01358 to 0.01170, saving model to model.hdf5\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 1742s 3s/step - loss: 0.0095 - val_loss: 0.0549\n",
      "\n",
      "Epoch 00001: loss improved from 0.01170 to 0.00947, saving model to model.hdf5\n",
      "Epoch 1/1\n",
      " 83/500 [===>..........................] - ETA: 26:04 - loss: 0.0100"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-32417fac2705>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                 \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                 callbacks=callbacks_list)\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_{}.h5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#file = ndrive.CreateFile({'title': 'model.hdf5'})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1251\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2210\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#todo meterle un offset de sesiones al generador para poder continuar training al cargar pesos\n",
    "for epoch in range(6, 11):\n",
    "    history = model.fit_generator(train_generator,\n",
    "                                steps_per_epoch=500,\n",
    "                                epochs=1,\n",
    "                                validation_data=dev_generator,\n",
    "                                validation_steps=35,\n",
    "                                callbacks=callbacks_list)\n",
    "    model.save_weights('model_{}.h5'.format(epoch))\n",
    "    #file = ndrive.CreateFile({'title': 'model.hdf5'})\n",
    "    #file.SetContentFile('./model.hdf5'.format(epoch))\n",
    "    #file.Upload() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ml9FmTh1cXvq"
   },
   "source": [
    "Epoch 1/10\n",
    "500/500 [==============================] - 3212s 6s/step - loss: 0.3575 - val_loss: 0.2090\n",
    "\n",
    "Epoch 00001: loss improved from inf to 0.35747, saving model to model.hdf5\n",
    "Epoch 2/10\n",
    "500/500 [==============================] - 3142s 6s/step - loss: 0.1088 - val_loss: 0.1369\n",
    "\n",
    "Epoch 00002: loss improved from 0.35747 to 0.10885, saving model to model.hdf5\n",
    "Epoch 3/10\n",
    "500/500 [==============================] - 3135s 6s/step - loss: 0.0647 - val_loss: 0.1010\n",
    "\n",
    "Epoch 00003: loss improved from 0.10885 to 0.06472, saving model to model.hdf5\n",
    "Epoch 4/10\n",
    "500/500 [==============================] - 3148s 6s/step - loss: 0.0407 - val_loss: 0.0711\n",
    "\n",
    "Epoch 00004: loss improved from 0.06472 to 0.04068, saving model to model.hdf5\n",
    "\n",
    "Epoch 5/10\n",
    "500/500 [==============================] - 3149s 6s/step - loss: 0.0291 - val_loss: 0.0674\n",
    "\n",
    "Epoch 00001: loss improved from 0.04068 to 0.02909, saving model to model.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "11GFp9PLSwKd"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# 1. Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "ndrive = GoogleDrive(gauth)\n",
    "\n",
    "file = ndrive.CreateFile({'title': 'model.hdf5'})\n",
    "file.SetContentFile('./model.hdf5')\n",
    "file.Upload() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wUg_4o1PbIRw"
   },
   "outputs": [],
   "source": [
    "3   10.5315\n",
    "4   10.5314\n",
    "8   10.5305\n",
    "13  10.5290\n",
    "21  10.5265\n",
    "62  10.4782\n",
    "74  10.4348\n",
    "174  9.8366\n",
    "287  9.3494"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-0kfDGI2FNSh",
    "outputId": "7e04de6b-ff54-497f-e808-00676064a9b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive  model.hdf5  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "birtbQ_kcgmo"
   },
   "outputs": [],
   "source": [
    "file.SetContentFile('./model.hdf5'.format(epoch))\n",
    "file.Upload() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SL6iBzAvqJjF",
    "outputId": "336bfd36-94ea-4f11-b7e5-3bef8cc3d251"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04967869857791811"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator = batch_generator(test_data, batch_size=batch_size)\n",
    "model.load_weights('./model_8.h5')\n",
    "model.evaluate_generator(test_generator, steps=400, max_queue_size=10, workers=1, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RcHAAJfMNJ3A"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IIC3633 Session RNNs v2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
