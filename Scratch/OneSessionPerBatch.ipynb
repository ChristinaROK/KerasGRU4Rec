{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhMT2zYloMpm"
   },
   "source": [
    "#**Proyecto - Sistemas Recomendadores - IIC3633**\n",
    "\n",
    "## Implementación en Keras de Session-Based RNNs for Recommendation con soft atenttion\n",
    "\n",
    "### V2: Implementación de embedding sobre one-hot vectors para entrenamiento más eficiente y modelo más chico\n",
    "\n",
    "\n",
    "Preliminar: Configuración entorno GPUs, Google Drive, entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "Z5dA3-L0nfLG",
    "outputId": "4a7a04f9-9aca-47fe-e79b-30baf6560196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# Manejo de Google Drive\n",
    "!pip install -U -q PyDrive\n",
    "\n",
    "from google.colab import drive, auth\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "drive.mount(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "6LGXgPsyoWsr",
    "outputId": "c6a26ac5-e483-431d-e774-e4de959f073d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gputil\n",
      "  Downloading https://files.pythonhosted.org/packages/45/99/837428d26b47ebd6b66d6e1b180e98ec4a557767a93a81a02ea9d6242611/GPUtil-1.3.0.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil) (1.14.6)\n",
      "Building wheels for collected packages: gputil\n",
      "  Running setup.py bdist_wheel for gputil ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/17/0f/04/b79c006972335e35472c0b835ed52bfc0815258d409f560108\n",
      "Successfully built gputil\n",
      "Installing collected packages: gputil\n",
      "Successfully installed gputil-1.3.0\n",
      "Collecting humanize\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/e0/e512e4ac6d091fc990bbe13f9e0378f34cf6eecd1c6c268c9e598dcf5bb9/humanize-0.5.1.tar.gz\n",
      "Building wheels for collected packages: humanize\n",
      "  Running setup.py bdist_wheel for humanize ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/69/86/6c/f8b8593bc273ec4b0c653d3827f7482bb2001a2781a73b7f44\n",
      "Successfully built humanize\n",
      "Installing collected packages: humanize\n",
      "Successfully installed humanize-0.5.1\n"
     ]
    }
   ],
   "source": [
    "# Librerias varias\n",
    "\n",
    "!pip install gputil\n",
    "!pip install humanize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3kJRW-qQ17_Q",
    "outputId": "1e336f48-43aa-4929-cefd-63e02dee3449"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import psutil\n",
    "import humanize\n",
    "import GPUtil as GPU\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import cosine_proximity, categorical_crossentropy\n",
    "from keras.models import Model, Sequential\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Input, Dense, Dropout, CuDNNGRU, Embedding, concatenate, Lambda, multiply\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "ik4GlGz8oZvj",
    "outputId": "bc42d34e-ecb5-4666-e44b-e89aea8c82f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 12.8 GB  I Proc size: 237.2 MB\n",
      "GPU RAM Free 7493MB | Used: 612MB | Util   8% | Total          8105MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('/device:GPU:0',\n",
       "  <google.protobuf.pyext._message.MessageDescriptor at 0x7ff7f70646b0>,\n",
       "  2,\n",
       "  1,\n",
       "  7)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuracion GPUs\n",
    "#!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "\n",
    "GPUs = GPU.getGPUs()\n",
    "gpu = GPUs[0]\n",
    "\n",
    "def print_gpu_info():\n",
    "  process = psutil.Process(os.getpid())\n",
    "  print(\"Gen RAM Free: \" + humanize.naturalsize(\n",
    "          psutil.virtual_memory().available), \" I Proc size: \"  +\n",
    "          humanize.naturalsize(process.memory_info().rss))\n",
    "  print(\"GPU RAM Free {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total \\\n",
    "         {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, \n",
    "                           gpu.memoryTotal))\n",
    "  \n",
    "print_gpu_info()\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [(x.name, x.DESCRIPTOR, x.DEVICE_TYPE_FIELD_NUMBER, x.NAME_FIELD_NUMBER, x.PHYSICAL_DEVICE_DESC_FIELD_NUMBER) for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfW00EfwSNQ6"
   },
   "outputs": [],
   "source": [
    "# Cargamos dataframes preprocesados de RSC15\n",
    "PATH_TO_TRAIN = '../processedData/rsc15_train_tr.txt'\n",
    "PATH_TO_DEV = '../processedData/rsc15_train_valid.txt'\n",
    "PATH_TO_TEST = '../processedData/rsc15_test.txt'\n",
    "\n",
    "train_data = pd.read_csv(PATH_TO_TRAIN, sep='\\t', dtype={'ItemId':np.int64})\n",
    "dev_data = pd.read_csv(PATH_TO_DEV, sep='\\t', dtype={'ItemId':np.int64})\n",
    "test_data = pd.read_csv(PATH_TO_TEST, sep='\\t', dtype={'ItemId': np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFkivhjnvrKO"
   },
   "outputs": [],
   "source": [
    "def batch_generator(data, batch_size=128, session_max_len=19, fraction=1, offset=0, embedding=True, n_items=None, itemids=None, itemidmap=None, aug = True):\n",
    "    item_key = 'ItemId'\n",
    "    session_key = 'SessionId'\n",
    "    time_key = 'Time'\n",
    "    \n",
    "    data = pd.merge(data, pd.DataFrame({item_key:itemids, 'ItemIdx':itemidmap[itemids].values}), on=item_key, how='inner') # agrego esa columna\n",
    "    \n",
    "    #print(\"Cantidad de samples: {}\".format(len(data)//fraction))\n",
    "\n",
    "    data.sort_values([session_key, time_key], inplace=True) # ordenamos por sesion\n",
    "\n",
    "    #data.sort_values([time_key], inplace=True)\n",
    "    length = len(data['ItemId'])\n",
    "    #data = data[length-length//fraction:]\n",
    "    \n",
    "    offset_sessions = np.zeros(data[session_key].nunique()+1, dtype=np.int32)\n",
    "    offset_sessions[1:] = data.groupby(session_key).size().cumsum() # arreglo con offset acumulativo de inicio de cada sesion\n",
    "    #offset_sessions = offset_sessions[length-length//fraction:]\n",
    "    \n",
    "    actual_session = 0 + offset\n",
    "    \n",
    "    batch_feats = None\n",
    "    batch_labels = None\n",
    "    # GRU_LAYER.reset_states() si usamos session parallel\n",
    "\n",
    "    while True:\n",
    "      datum = data[offset_sessions[actual_session]:offset_sessions[actual_session+1]][item_key]  # aqui toda la info de la sesion\n",
    "      datum = datum.values.reshape(-1,1)           \n",
    "      for i in range(offset_sessions[actual_session+1]-offset_sessions[actual_session]-1):\n",
    "        if not aug:\n",
    "          if (i != offset_sessions[actual_session+1]-offset_sessions[actual_session]-2):\n",
    "            continue\n",
    "        feats = datum[0:i+1]\n",
    "   \n",
    "        if feats.shape[0] > session_max_len:\n",
    "            feats = feats[:session_max_len] # aca cambiar a mas nuevos\n",
    "        else:\n",
    "            feats = np.append(np.zeros((session_max_len-feats.shape[0],1), dtype=np.int8), feats) # left pad with zeros\n",
    "\n",
    "        feats = feats.reshape(1,-1) # (1, 19)\n",
    "\n",
    "        label = datum[i+1]\n",
    "        label = np.expand_dims(label, axis=0)  # Termina siendo (1, dimn_previa)\n",
    "\n",
    "        if not isinstance(batch_feats, type(feats)):\n",
    "            batch_feats = feats\n",
    "        else:\n",
    "            if batch_labels.shape[0] < batch_size:\n",
    "                batch_feats = np.append(batch_feats, feats, axis=0)\n",
    "\n",
    "        if not isinstance(batch_labels, type(label)):\n",
    "            batch_labels = label\n",
    "        else:\n",
    "            if batch_labels.shape[0] < batch_size:\n",
    "                batch_labels = np.append(batch_labels, label, axis=0)\n",
    "\n",
    "        #print(batch_feats)\n",
    "        #print(batch_labels)\n",
    "        \n",
    "        #if batch_labels.shape[0] == batch_size:\n",
    "        #if not embedding:\n",
    "            # batch_labels.shape = (batch_size, 1)\n",
    "            #new_labels = np.zeros((batch_size, n_items))\n",
    "            #new_labels[0][:] = to_categorical(itemidmap[label[0][0]], num_classes=n_items)\n",
    "        #    batch_labels = to_categorical(itemidmap[batch_labels.flatten()], num_classes=n_items)\n",
    "            #print(\"Yielding batch with shape {} train, {} target\".format(batch_feats.shape, batch_labels.shape))\n",
    "            #pass\n",
    "\n",
    "        #yield batch_feats, batch_labels\n",
    "        # resume batch generation\n",
    "        #batch_feats = None\n",
    "        #batch_labels = None\n",
    "\n",
    "    # TODO: Dropout random como en el paper\n",
    "\n",
    "    actual_session = (actual_session + 1) % len(offset_sessions)\n",
    "    print(\"Yielding batch with shape {} train, {} target\".format(batch_feats.shape, batch_labels.shape))\n",
    "    yield batch_feats, batch_labels\n",
    "    # resume batch generation\n",
    "    batch_feats = None\n",
    "    batch_labels = None\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "eQslL5CpRjdQ",
    "outputId": "bd8d7ef2-638d-42a1-eaf5-6e96636a7be7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items unicos training: 37484\n",
      "Items unicos dev: 6360\n",
      "Items unicos testing: 6752\n",
      "Sesiones training: 7953885\n",
      "Sesiones validation: 12372\n",
      "Sesiones testing: 15324\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512 #como en el paper\n",
    "session_max_len = 19\n",
    "embeddingp=False\n",
    "\n",
    "n_items = len(train_data['ItemId'].unique())+1\n",
    "print(\"Items unicos training:\", n_items)\n",
    "\n",
    "dev_n_items = len(dev_data['ItemId'].unique())+1\n",
    "print(\"Items unicos dev:\", dev_n_items)\n",
    "\n",
    "test_n_items = len(test_data['ItemId'].unique())+1\n",
    "print(\"Items unicos testing:\", test_n_items)\n",
    "\n",
    "train_samples_qty = len(train_data['SessionId'].unique()) # cantidad sesiones no augmentadas de train\n",
    "print(\"Sesiones training:\", train_samples_qty)\n",
    "\n",
    "dev_samples_qty = len(dev_data['SessionId'].unique()) # cantidad sesiones no augmentadas de dev\n",
    "print(\"Sesiones validation:\",dev_samples_qty)\n",
    "\n",
    "test_samples_qty = len(test_data['SessionId'].unique()) # cantidad sesiones no augmentadas de test\n",
    "print(\"Sesiones testing:\", test_samples_qty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1i_adI_ASgDi"
   },
   "outputs": [],
   "source": [
    "train_fraction = 1#256 # 1/fraction es la cantidad de sesiones mas recientes a considerar\n",
    "dev_fraction = 1#2\n",
    "\n",
    "train_offset_step=35000#40000#15530\n",
    "dev_offset_step=65#240\n",
    "\n",
    "\n",
    "aux = [0]\n",
    "aux.extend(list(train_data['ItemId'].unique()))\n",
    "itemids = np.array(aux)\n",
    "itemidmap = pd.Series(data=np.arange(n_items), index=itemids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "O5_sa72xSF50",
    "outputId": "b1a69ec9-6e86-44ba-d19e-69fe1f59cf57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 19)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 19, 50)            1874200   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 19, 50)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 100)               45600     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 37484)             3785884   \n",
      "=================================================================\n",
      "Total params: 5,705,684\n",
      "Trainable params: 5,705,684\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcerdam/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/ipykernel_launcher.py:53: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "\n",
    "# ToDo:\n",
    "# meterle self-attention (hay implementaciones en Keras)\n",
    "\n",
    "def custom_cosine_loss(itemidmap, n_items):\n",
    "    #emb = model.layers[1]\n",
    "    emb = itemidmap\n",
    "    nu_items = n_items\n",
    "    # y_pred ya viene con embedding, y_true solo como one-hot\n",
    "    def fn(y_true, y_pred):\n",
    "        #print(y_true.shape, y_pred.shape)\n",
    "        y_pred_emb = to_categorical(emb[y_pred], num_classes=nu_items)\n",
    "        #print(y_true_emb)\n",
    "        #y_pred_emb = emb.call(y_pred)\n",
    "\n",
    "    #y_true_emb = np.array([y_true], dtype='int32')\n",
    "    #y_true_emb = tf.convert_to_tensor(y_true_emb)\n",
    "    #y_true_emb = model.layers[0].call(y_true)\n",
    "    #y_true_emb = K.get_value(y_true_emb)[0][0] # 50,\n",
    "\n",
    "        return 1 - cosine_proximity(y_true, y_pred_emb)\n",
    "        #return cosine_proximity(y_true_emb, y_pred_emb)\n",
    "    return fn\n",
    "    \n",
    "emb_size = 50\n",
    "size = emb_size\n",
    "#size = emb_size if embeddingp else n_items\n",
    "\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "emb = Embedding(n_items, emb_size, embeddings_initializer='uniform', input_length=19)\n",
    "model.add(emb)\n",
    "model.add(Dropout(0.25))\n",
    "model.add(CuDNNGRU(1000)) \n",
    "model.add(Dropout(0.25))\n",
    "if embeddingp:\n",
    "    model.add(Dense(emb_size, activation='softmax'))\n",
    "    custom_loss = custom_cosine_loss(emb)  ## DUDA: Esta usando los pesos actuales?\n",
    "    model.compile(loss=custom_loss, optimizer='adam')\n",
    "else:\n",
    "    model.add(Dense(n_items, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()\n",
    "\"\"\"\n",
    "\n",
    "inputs = Input(shape=(19,))\n",
    "emb = Embedding(n_items, emb_size, embeddings_initializer='uniform', input_length=19)(inputs)\n",
    "drop1 = Dropout(0.25)(emb)\n",
    "gru = CuDNNGRU(100)(drop1)\n",
    "drop2 = Dropout(0.25)(gru)\n",
    "predictions = Dense(n_items, activation='softmax')(drop2)\n",
    "model = Model(input=inputs, output=[predictions])\n",
    "custom_loss = custom_cosine_loss(itemidmap, n_items)\n",
    "opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "# Try Nadam, too\n",
    "model.compile(loss=categorical_crossentropy, optimizer=opt)\n",
    "model.summary()\n",
    "\n",
    "filepath='./OneSessionPerBatch/model_checkpoint'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=2, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "1XFQrjF7TZlU",
    "outputId": "9c209770-d67a-4bb3-a0ac-ed2a2a65fc0e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2211\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2287\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0menqueuer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2288\u001b[0;31m                     \u001b[0menqueuer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2289\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0;31m# always, which is ok no matter what the status of the thread.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                 \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-676c3eedf92a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                 \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_offset_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#105,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                                 callbacks=callbacks_list)\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2289\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2290\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval_enqueuer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2291\u001b[0;31m                     \u001b[0mval_enqueuer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2293\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0;31m# join, rendering this test meaningless -> Call thread.join()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0;31m# always, which is ok no matter what the status of the thread.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                 \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "real_epoca = 0\n",
    "for epoch in range(1):\n",
    "    try:\n",
    "        model.load_weights('./bast/model_{}'.format(real_epoca-1))\n",
    "    except:\n",
    "        pass\n",
    "    train_generator = batch_generator(train_data, \n",
    "                                      batch_size=batch_size, \n",
    "                                      fraction=train_fraction, \n",
    "                                      offset=train_offset_step*epoch,\n",
    "                                     embedding=embeddingp,\n",
    "                                      n_items=n_items,\n",
    "                                     itemids=itemids,\n",
    "                                     itemidmap=itemidmap)\n",
    "    \n",
    "    dev_generator = batch_generator(dev_data, \n",
    "                                    batch_size=batch_size, \n",
    "                                    fraction=dev_fraction, \n",
    "                                    offset=dev_offset_step*epoch,\n",
    "                                    embedding=embeddingp,\n",
    "                                    n_items=n_items,\n",
    "                                    itemids=itemids,\n",
    "                                     itemidmap=itemidmap)\n",
    "    \n",
    "    history = model.fit_generator(train_generator,\n",
    "                                steps_per_epoch=train_offset_step,#15530,\n",
    "                                epochs=1,\n",
    "                                validation_data=dev_generator,\n",
    "                                validation_steps=dev_offset_step,#105,\n",
    "                                callbacks=callbacks_list)\n",
    "    \n",
    "    model.save_weights(filepath)\n",
    "    \n",
    "    weights = model.layers[1].get_weights()[0]\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    nbrs = NearestNeighbors(n_neighbors=20, algorithm='ball_tree').fit(weights)\n",
    "    distances, indices = nbrs.kneighbors(weights) # Vienen ya ordenados! # Shape (37484, 20)\n",
    "    # Paso 3: Dado un vector embedding arbitrario, obtener el item más cercano a éste. Aplicarla sobre los 20 anteriores.\n",
    "    from sklearn.metrics import recall_score\n",
    "\n",
    "    test_generator = batch_generator(test_data, \n",
    "                                      batch_size=batch_size, \n",
    "                                      fraction=train_fraction, \n",
    "                                      offset=0,\n",
    "                                     embedding=embeddingp,\n",
    "                                      n_items=n_items,\n",
    "                                     itemids=itemids,\n",
    "                                     itemidmap=itemidmap)\n",
    "\n",
    "\n",
    "    n = 0\n",
    "    suma = 0\n",
    "    while True:\n",
    "          try:\n",
    "            test_batch = next(test_generator)\n",
    "            pred = model.predict(test_batch[0]) # batch_size, n_items => 512, 37484\n",
    "            label = test_batch[1]               \n",
    "\n",
    "            #print(pred.shape)\n",
    "            #print(label.shape) \n",
    "\n",
    "            for row_idx in range(test_batch[0].shape[0]):\n",
    "              pred_row = pred[row_idx] # 37484, #.reshape(1, -1) # 50,\n",
    "              label_row = label[row_idx]        #.reshape(1, -1) # 50,\n",
    "\n",
    "              #print(pred_row.shape)\n",
    "              #print(label_row.shape)\n",
    "\n",
    "              idx1 = pred_row.argsort()[-20:][::-1]\n",
    "              idx2 = label_row.argsort()[-1:][::-1]\n",
    "\n",
    "              n += 1\n",
    "              #print(idx1)\n",
    "              #print(idx2)\n",
    "              if idx2[0] in idx1:\n",
    "                suma += 1\n",
    "\n",
    "          except:\n",
    "            break\n",
    "    print(\"Recall epoch {}: {}\".format(epoch, suma/n))\n",
    "    real_epoca += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath='./OneSessionPerBatch/model_{}'.format(epoch)\n",
    "model.save_weights(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Started @ 9.2\n",
    "\n",
    "En 8.01 se puso lento... ojo\n",
    "\n",
    "Goin up 7.8464\n",
    "\n",
    "Epoch time: 2:00 aprox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall epoch 0: 0.009550602064220183\n"
     ]
    }
   ],
   "source": [
    "weights = model.layers[1].get_weights()[0]\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=20, algorithm='ball_tree').fit(weights)\n",
    "distances, indices = nbrs.kneighbors(weights) # Vienen ya ordenados! # Shape (37484, 20)\n",
    "# Paso 3: Dado un vector embedding arbitrario, obtener el item más cercano a éste. Aplicarla sobre los 20 anteriores.\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "test_generator = batch_generator(test_data, \n",
    "                                  batch_size=batch_size, \n",
    "                                  fraction=train_fraction, \n",
    "                                  offset=0,\n",
    "                                 embedding=embeddingp,\n",
    "                                  n_items=n_items,\n",
    "                                 itemids=itemids,\n",
    "                                 itemidmap=itemidmap)\n",
    "\n",
    "\n",
    "n = 0\n",
    "suma = 0\n",
    "while True:\n",
    "  try:\n",
    "    test_batch = next(test_generator)\n",
    "    pred = model.predict(test_batch[0]) # batch_size, n_items => 512, 37484\n",
    "    label = test_batch[1]               \n",
    "\n",
    "    #print(pred.shape)\n",
    "    #print(label.shape) \n",
    "\n",
    "    for row_idx in range(test_batch[0].shape[0]):\n",
    "      pred_row = pred[row_idx] # 37484, #.reshape(1, -1) # 50,\n",
    "      label_row = label[row_idx]        #.reshape(1, -1) # 50,\n",
    "\n",
    "      #print(pred_row.shape)\n",
    "      #print(label_row.shape)\n",
    "\n",
    "      idx1 = pred_row.argsort()[-20:][::-1]\n",
    "      idx2 = label_row.argsort()[-1:][::-1]\n",
    "\n",
    "      n += 1\n",
    "      #print(idx1)\n",
    "      #print(idx2)\n",
    "      if idx2[0] in idx1:\n",
    "        suma += 1\n",
    "\n",
    "  except:\n",
    "    break\n",
    "print(\"Recall epoch {}: {}\".format(epoch, suma/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall epoch 0: 0.0005554759174311927 # seste se disparo y lo corte\n",
    "\n",
    "Recall epoch 0: 0.009550602064220183 # primera con lr mas bajo\n",
    "Recall epoch 1: 0.009084719036697247\n",
    "\n",
    "# TODO\n",
    "\n",
    "## Batcher solo entrega una sesion a la vez, si no se pierde independencia"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IIC3633_M1_Colab_V2.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
