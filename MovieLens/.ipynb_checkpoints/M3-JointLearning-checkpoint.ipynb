{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhMT2zYloMpm"
   },
   "source": [
    "#**Proyecto - Sistemas Recomendadores - IIC3633**\n",
    "\n",
    "## Implementaci칩n en Keras de Session-Based RNNs for Recommendation con soft atenttion\n",
    "\n",
    "### V2: Implementaci칩n de embedding sobre one-hot vectors para entrenamiento m치s eficiente y modelo m치s chico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3kJRW-qQ17_Q",
    "outputId": "1e336f48-43aa-4929-cefd-63e02dee3449"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import psutil\n",
    "import humanize\n",
    "import pyreclab\n",
    "import GPUtil as GPU\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import cosine_proximity, categorical_crossentropy\n",
    "from keras.models import Model, Sequential\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers.core import Permute, Reshape, RepeatVector\n",
    "from keras.layers import Input, Dense, Dropout, CuDNNGRU, Embedding, concatenate, Lambda, multiply, merge, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfW00EfwSNQ6"
   },
   "outputs": [],
   "source": [
    "# Cargamos dataframes preprocesados de MovieLens20MM\n",
    "PATH_TO_TRAIN = './data/all_train.csv'\n",
    "PATH_TO_DEV = './data/dev.csv'\n",
    "PATH_TO_TEST = './data/test.csv'\n",
    "\n",
    "train_data = pd.read_csv(PATH_TO_TRAIN, sep='\\t', dtype={'ItemId':np.int64})\n",
    "dev_data = pd.read_csv(PATH_TO_DEV, sep='\\t', dtype={'ItemId':np.int64})\n",
    "test_data = pd.read_csv(PATH_TO_TEST, sep='\\t', dtype={'ItemId': np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFkivhjnvrKO"
   },
   "outputs": [],
   "source": [
    "def batch_generator(data, batch_size=128, session_max_len=19, fraction=1, offset=0, embedding=True, n_items=None, itemids=None, itemidmap=None, aug = True):\n",
    "    item_key = 'ItemId'\n",
    "    session_key = 'SessionId'\n",
    "    time_key = 'Time'\n",
    "    \n",
    "    # add column\n",
    "    data = pd.merge(data, pd.DataFrame({item_key:itemids, 'ItemIdx':itemidmap[itemids].values}), on=item_key, how='inner') \n",
    "\n",
    "    # sort by session\n",
    "    data.sort_values([session_key, time_key], inplace=True) \n",
    "\n",
    "    length = len(data['ItemId'])\n",
    "    \n",
    "    # array with cummulative offset that gives each session start in the array\n",
    "    offset_sessions = np.zeros(data[session_key].nunique()+1, dtype=np.int32)\n",
    "    offset_sessions[1:] = data.groupby(session_key).size().cumsum() \n",
    "    \n",
    "    actual_session = 0 + offset\n",
    "    \n",
    "    batch_feats = None\n",
    "    batch_labels = None\n",
    "\n",
    "    while True:\n",
    "        # session info\n",
    "        datum = data[offset_sessions[actual_session]:offset_sessions[actual_session+1]][item_key]  \n",
    "        datum = datum.values.reshape(-1,1)          \n",
    "        \n",
    "        for i in range(offset_sessions[actual_session+1]-offset_sessions[actual_session]-1):\n",
    "            if not aug:\n",
    "                if (i != offset_sessions[actual_session+1]-offset_sessions[actual_session]-2):\n",
    "                    continue\n",
    "                    \n",
    "            feats = datum[0:i+1]\n",
    "\n",
    "            if feats.shape[0] > session_max_len:\n",
    "                # take newest events\n",
    "                feats = feats[feats.shape[0]-session_max_len:] \n",
    "            else:\n",
    "                # left pad with zeros\n",
    "                feats = np.append(np.zeros((session_max_len-feats.shape[0],1), dtype=np.int8), feats)\n",
    "\n",
    "            feats = feats.reshape(1,-1) \n",
    "            feats = np.expand_dims(feats, axis=2)\n",
    "            label = datum[i+1]\n",
    "            label = np.expand_dims(label, axis=0)  # Termina siendo (1, dimn_previa)\n",
    "\n",
    "            if not isinstance(batch_feats, type(feats)):\n",
    "                batch_feats = feats\n",
    "            else:\n",
    "                batch_feats = np.append(batch_feats, feats, axis=0)\n",
    "\n",
    "            if not isinstance(batch_labels, type(label)):\n",
    "                batch_labels = label\n",
    "            else:\n",
    "                batch_labels = np.append(batch_labels, label, axis=0)\n",
    "\n",
    "\n",
    "            if batch_labels.shape[0] == batch_size:\n",
    "                if not embedding:\n",
    "                    batch_labels = to_categorical(itemidmap[batch_labels.flatten()], num_classes=n_items)\n",
    "                    pass\n",
    "\n",
    "                yield batch_feats, batch_labels\n",
    "                \n",
    "                # resume batch generation\n",
    "                batch_feats = None\n",
    "                batch_labels = None\n",
    "\n",
    "        actual_session = (actual_session + 1) % len(offset_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "eQslL5CpRjdQ",
    "outputId": "bd8d7ef2-638d-42a1-eaf5-6e96636a7be7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items unicos training: 12811\n",
      "Items unicos dev: 10103\n",
      "Items unicos testing: 10365\n",
      "Sesiones training: 80466\n",
      "Sesiones validation: 5747\n",
      "Sesiones testing: 5270\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512 #como en el paper\n",
    "session_max_len = 100\n",
    "embeddingp=False\n",
    "\n",
    "n_items = len(train_data['ItemId'].unique())+1\n",
    "print(\"Items unicos training:\", n_items)\n",
    "\n",
    "dev_n_items = len(dev_data['ItemId'].unique())+1\n",
    "print(\"Items unicos dev:\", dev_n_items)\n",
    "\n",
    "test_n_items = len(test_data['ItemId'].unique())+1\n",
    "print(\"Items unicos testing:\", test_n_items)\n",
    "\n",
    "train_samples_qty = len(train_data['SessionId'].unique()) # cantidad sesiones no augmentadas de train\n",
    "print(\"Sesiones training:\", train_samples_qty)\n",
    "\n",
    "dev_samples_qty = len(dev_data['SessionId'].unique()) # cantidad sesiones no augmentadas de dev\n",
    "print(\"Sesiones validation:\",dev_samples_qty)\n",
    "\n",
    "test_samples_qty = len(test_data['SessionId'].unique()) # cantidad sesiones no augmentadas de test\n",
    "print(\"Sesiones testing:\", test_samples_qty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1i_adI_ASgDi"
   },
   "outputs": [],
   "source": [
    "train_fraction = 1#256 # 1/fraction es la cantidad de sesiones mas recientes a considerar\n",
    "dev_fraction = 1#2\n",
    "\n",
    "train_offset_step=train_samples_qty//batch_size\n",
    "dev_offset_step=dev_samples_qty//batch_size\n",
    "test_offset_step=test_samples_qty//batch_size\n",
    "\n",
    "\n",
    "aux = [0]\n",
    "aux.extend(list(train_data['ItemId'].unique()))\n",
    "itemids = np.array(aux)\n",
    "itemidmap = pd.Series(data=np.arange(n_items), index=itemids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "O5_sa72xSF50",
    "outputId": "b1a69ec9-6e86-44ba-d19e-69fe1f59cf57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcerdam/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/ipykernel_launcher.py:15: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only layers of same output shape can be merged using mul mode. Layer shapes: [(None, 100, 100), (None, 10, 100)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5a1d77f0c0da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mgru\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCuDNNGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# drop1) #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mdrop2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mattention_mul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_3d_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mattention_mul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#(drop2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-5a1d77f0c0da>\u001b[0m in \u001b[0;36mattention_3d_block\u001b[0;34m(inputs, TIME_STEPS, SINGLE_ATTENTION_VECTOR)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepeatVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0ma_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'attention_vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0moutput_attention_mul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_probs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'attention_mul'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mul'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput_attention_mul\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(inputs, mode, concat_axis, dot_axes, output_shape, output_mask, arguments, name)\u001b[0m\n\u001b[1;32m    462\u001b[0m                             \u001b[0mnode_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m                             \u001b[0mtensor_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                             name=name)\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, mode, concat_axis, dot_axes, output_shape, output_mask, arguments, node_indices, tensor_indices, name)\u001b[0m\n\u001b[1;32m    115\u001b[0m             self._arguments_validation(layers, mode,\n\u001b[1;32m    116\u001b[0m                                        \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdot_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                                        node_indices, tensor_indices)\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/KerasRecSysPy3/lib/python3.5/site-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36m_arguments_validation\u001b[0;34m(self, layers, mode, concat_axis, dot_axes, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 raise ValueError('Only layers of same output shape can '\n\u001b[1;32m    160\u001b[0m                                  \u001b[0;34m'be merged using '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' mode. '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                                  'Layer shapes: %s' % input_shapes)\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'cos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dot'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only layers of same output shape can be merged using mul mode. Layer shapes: [(None, 100, 100), (None, 10, 100)]"
     ]
    }
   ],
   "source": [
    "# Modelo\n",
    "\n",
    "# ToDo: self-attention\n",
    "\n",
    "def attention_3d_block(inputs, TIME_STEPS, SINGLE_ATTENTION_VECTOR=True):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    #a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
    "    return output_attention_mul\n",
    "    \n",
    "emb_size = 50\n",
    "size = emb_size\n",
    "#size = emb_size if embeddingp else n_items\n",
    "\n",
    "inputs = Input(shape=(session_max_len,1))\n",
    "#emb = Embedding(n_items, emb_size, embeddings_initializer='uniform', input_length=session_max_len)(inputs)\n",
    "#drop1 = Dropout(0.25)(emb)\n",
    "gru = CuDNNGRU(10, return_sequences=True)(inputs)# drop1) #\n",
    "drop2 = Dropout(0.25)(gru)\n",
    "attention_mul = attention_3d_block(drop2, session_max_len)\n",
    "attention_mul = Flatten()(attention_mul)\n",
    "predictions = Dense(n_items, activation='softmax')(attention_mul)#(drop2)\n",
    "model = Model(input=inputs, output=[predictions])\n",
    "#custom_loss = custom_cosine_loss(itemidmap, n_items)\n",
    "# lr original es 0.0001\n",
    "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "# Try Nadam, too\n",
    "model.compile(loss=categorical_crossentropy, optimizer=opt)\n",
    "model.summary()\n",
    "\n",
    "#filepath='./bast/model_checkpoint'\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=2, save_best_only=True, mode='min')\n",
    "callbacks_list = []#[checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "1XFQrjF7TZlU",
    "outputId": "9c209770-d67a-4bb3-a0ac-ed2a2a65fc0e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 7.6020 - val_loss: 8.4168\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 9s 60ms/step - loss: 7.1930 - val_loss: 8.3621\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 7.0657 - val_loss: 8.4034\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 6.9482 - val_loss: 8.3910\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 9s 60ms/step - loss: 6.8318 - val_loss: 8.4126\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 9s 60ms/step - loss: 6.7505 - val_loss: 8.4395\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 9s 60ms/step - loss: 6.7064 - val_loss: 8.4877\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 6.6609 - val_loss: 8.5395\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 6.6533 - val_loss: 8.4551\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 63ms/step - loss: 6.6190 - val_loss: 8.4316\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 63ms/step - loss: 6.6153 - val_loss: 8.4056\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 9s 60ms/step - loss: 6.6310 - val_loss: 8.3188\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 9s 60ms/step - loss: 6.6340 - val_loss: 8.1866\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 6.6336 - val_loss: 8.1280\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 6.6455 - val_loss: 8.1382\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 6.6208 - val_loss: 8.0796\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 6.6161 - val_loss: 8.1147\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 63ms/step - loss: 6.6320 - val_loss: 8.1778\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 63ms/step - loss: 6.6312 - val_loss: 8.1716\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 63ms/step - loss: 6.6298 - val_loss: 8.0896\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 6.6305 - val_loss: 8.1462\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 6.6457 - val_loss: 8.0822\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 6.6077 - val_loss: 8.0706\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 6.5865 - val_loss: 8.1432\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 6.6003 - val_loss: 8.1922\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 63ms/step - loss: 6.5974 - val_loss: 8.2510\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 9s 60ms/step - loss: 6.5840 - val_loss: 8.3582\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 9s 60ms/step - loss: 6.5690 - val_loss: 8.4208\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 9s 60ms/step - loss: 6.5618 - val_loss: 8.4857\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 9s 60ms/step - loss: 6.5528 - val_loss: 8.5923\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 6.5629 - val_loss: 8.4733\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 6.5827 - val_loss: 8.4430\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 6.5634 - val_loss: 8.4566\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 6.5646 - val_loss: 8.4375\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 6.5930 - val_loss: 8.4219\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 6.5666 - val_loss: 8.3973\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 9s 60ms/step - loss: 6.5615 - val_loss: 8.2715\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 6.5798 - val_loss: 8.2956\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 6.5596 - val_loss: 8.2657\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 6.5805 - val_loss: 8.3680\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 6.5920 - val_loss: 8.3664\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 9s 59ms/step - loss: 6.5822 - val_loss: 8.3161\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 6.5603 - val_loss: 8.3725\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 6.5546 - val_loss: 8.3821\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 6.5670 - val_loss: 8.3574\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 63ms/step - loss: 6.5343 - val_loss: 8.3134\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 63ms/step - loss: 6.5233 - val_loss: 8.3167\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 9s 59ms/step - loss: 6.5239 - val_loss: 8.3097\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 9s 60ms/step - loss: 6.5205 - val_loss: 8.3520\n",
      "Epoch 1/1\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 6.5200 - val_loss: 8.3234\n"
     ]
    }
   ],
   "source": [
    "real_epoca = 1\n",
    "for epoch in range(50):\n",
    "    #filepath='./weights/model_{}'.format(real_epoca)\n",
    "    #model.load_weights('./weights/model_{}'.format(real_epoca-1))\n",
    "    #model.save_weights(filepath)\n",
    "    train_generator = batch_generator(train_data, \n",
    "                                      batch_size=batch_size, \n",
    "                                  session_max_len=session_max_len,\n",
    "                                      fraction=train_fraction, \n",
    "                                      offset=train_offset_step*epoch,\n",
    "                                     embedding=embeddingp,\n",
    "                                      n_items=n_items,\n",
    "                                     itemids=itemids,\n",
    "                                     itemidmap=itemidmap)\n",
    "    \n",
    "    dev_generator = batch_generator(dev_data, \n",
    "                                    batch_size=batch_size,\n",
    "                                  session_max_len=session_max_len,\n",
    "                                    fraction=dev_fraction, \n",
    "                                    offset=dev_offset_step*epoch,\n",
    "                                    embedding=embeddingp,\n",
    "                                    n_items=n_items,\n",
    "                                    itemids=itemids,\n",
    "                                     itemidmap=itemidmap)\n",
    "    \n",
    "    history = model.fit_generator(train_generator,\n",
    "                                steps_per_epoch=train_offset_step,\n",
    "                                epochs=1,\n",
    "                                validation_data=dev_generator,\n",
    "                                validation_steps=dev_offset_step,\n",
    "                                callbacks=callbacks_list)\n",
    "    \n",
    "    real_epoca += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "12800\n",
      "25600\n",
      "38400\n",
      "51200\n",
      "64000\n",
      "76800\n",
      "89600\n",
      "102400\n",
      "115200\n",
      "128000\n",
      "140800\n",
      "153600\n",
      "166400\n",
      "Recall@20 epoch 49: 0.09473825785928144\n"
     ]
    }
   ],
   "source": [
    "weights = model.layers[1].get_weights()[0]\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# RECALL @ 10\n",
    "recall_k = 20\n",
    "\n",
    "#nbrs = NearestNeighbors(n_neighbors=recall_k, algorithm='ball_tree').fit(weights)\n",
    "#distances, indices = nbrs.kneighbors(weights) # Vienen ya ordenados! # Shape (37484, 20)\n",
    "# Paso 3: Dado un vector embedding arbitrario, obtener el item m치s cercano a 칠ste. Aplicarla sobre los 20 anteriores.\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "test_generator = batch_generator(test_data, \n",
    "                                  batch_size=batch_size,\n",
    "                                  session_max_len=session_max_len,\n",
    "                                  fraction=train_fraction, \n",
    "                                  offset=0,\n",
    "                                 embedding=embeddingp,\n",
    "                                  n_items=n_items,\n",
    "                                 itemids=itemids,\n",
    "                                 itemidmap=itemidmap)\n",
    "\n",
    "\n",
    "n = 0\n",
    "suma = 0\n",
    "suma_baseline = 0\n",
    "while True:\n",
    "    try:\n",
    "        test_batch = next(test_generator)\n",
    "        pred = model.predict(test_batch[0]) # batch_size, n_items => 512, 37484\n",
    "        \n",
    "\n",
    "        label = test_batch[1]               \n",
    "\n",
    "        if n%100 == 0:\n",
    "            print(n)\n",
    "        #print(pred.shape)\n",
    "        #print(label.shape) \n",
    "\n",
    "        for row_idx in range(test_batch[0].shape[0]):\n",
    "          #print(test_batch[0][row_idx])\n",
    "          #baseline_pred = obj.recommend( str(test_batch[0][row_idx][-1]), 20 )\n",
    "          pred_row = pred[row_idx] # 37484, #.reshape(1, -1) # 50,\n",
    "          label_row = label[row_idx]        #.reshape(1, -1) # 50,\n",
    "\n",
    "          #print(pred_row.shape)\n",
    "          #print(label_row.shape)\n",
    "\n",
    "          idx1 = pred_row.argsort()[-recall_k:][::-1]\n",
    "          idx2 = label_row.argsort()[-1:][::-1]\n",
    "\n",
    "          n += 1\n",
    "          #print(idx1)\n",
    "          #print(idx2)\n",
    "          if idx2[0] in idx1:\n",
    "            suma += 1\n",
    "\n",
    "          #if idx2[0] in baseline_pred:\n",
    "          #  suma_baseline += 1\n",
    "\n",
    "    except:\n",
    "        break\n",
    "print(\"Recall@{} epoch {}: {}\".format(recall_k, epoch, suma/n))\n",
    "\n",
    "#print(\"Recall@{} baseline: {}\".format(recall_k, suma_baseline/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All train set\n",
    "Recall@10 epoch 29: 0.08087340943113773\n",
    "Recall@20: 0.10473194236526946\n",
    "\n",
    "vs Hidasi\n",
    "\n",
    "Recall @ 20 0.2177499329156604\n",
    "MRR@20: 0.06513681594077811\n",
    "\n",
    "Pruebas atencion\n",
    "Baseline\n",
    "Recall@20 epoch 49: 0.09473825785928144\n",
    "MultAttn\n",
    "\n",
    "\n",
    "\n",
    "# Train Set\n",
    "Recall@10 epoch ..100?: 0.09546921781437126\n",
    "\n",
    "Recall@10 epoch 14: 0.06404879908501715\n",
    "\n",
    "Recall @20 epoch 99: 0.08705440681137724\n",
    "\n",
    "Con session_max_len = 100:\n",
    "\n",
    "Recall @20 epoch 9: 0.12195335890718563\n",
    "\n",
    "Con dwell_time NO FUNCIONA BIEN. Hacer ese supuesto en este dataset no tiene sentido.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IIC3633_M1_Colab_V2.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
