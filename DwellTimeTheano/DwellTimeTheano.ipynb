{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhMT2zYloMpm"
   },
   "source": [
    "#**Proyecto - Sistemas Recomendadores - IIC3633**\n",
    "\n",
    "## ImplementaciÃ³n de Dwell Time en GRU4REC\n",
    "\n",
    "\n",
    "Ejecucion local MacBook Air, y sobre val_set. Esto para que el modelo aprenda a predecir el Dwell Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfW00EfwSNQ6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load RSC15 preprocessed train dataframe\n",
    "#PATH_TO_TRAIN = '../processedData/rsc15_train_tr.txt'\n",
    "#train_data = pd.read_csv(PATH_TO_TRAIN, sep='\\t', dtype={'ItemId':np.int64})\n",
    "PATH_TO_VAL = '../processedData/rsc15_train_valid.txt'\n",
    "val_data = pd.read_csv(PATH_TO_VAL, sep='\\t', dtype={'ItemId':np.int64})\n",
    "\n",
    "train_data = val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_df(df):    \n",
    "    \n",
    "    n_items = len(train_data['ItemId'].unique())\n",
    "    aux = list(train_data['ItemId'].unique())\n",
    "    itemids = np.array(aux)\n",
    "    itemidmap = pd.Series(data=np.arange(n_items), index=itemids)  # (id_item => (0, n_items))\n",
    "    \n",
    "    item_key = 'ItemId'\n",
    "    session_key = 'SessionId'\n",
    "    time_key = 'Time'\n",
    "    \n",
    "    data = pd.merge(df, pd.DataFrame({item_key:itemids, 'ItemIdx':itemidmap[itemids].values}), on=item_key, how='inner')\n",
    "    data.sort_values([session_key, time_key], inplace=True)\n",
    "\n",
    "    length = len(data['ItemId'])\n",
    "        \n",
    "    return data\n",
    "    \n",
    "    \n",
    "new_df = preprocess_df(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_dwell_time(df):\n",
    "   \n",
    "    times_t = np.roll(df['Time'], -1) # Take time row\n",
    "    times_dt  = df['Time']            # Copy, then displace by one\n",
    "    \n",
    "    diffs = np.subtract(times_t, times_dt) # Take the pairwise difference\n",
    "    \n",
    "    length = len(df['ItemId'])\n",
    "    \n",
    "    # cummulative offset start for each session\n",
    "    offset_sessions = np.zeros(df['SessionId'].nunique()+1, dtype=np.int32)\n",
    "    offset_sessions[1:] = df.groupby('SessionId').size().cumsum() \n",
    "    \n",
    "    offset_sessions = offset_sessions - 1\n",
    "    offset_sessions = np.roll(offset_sessions, -1)\n",
    "    \n",
    "    # session transition implies zero-dwell-time\n",
    "    # note: paper statistics do not consider null entries, \n",
    "    # though they are still checked when augmenting\n",
    "    np.put(diffs, offset_sessions, np.zeros((offset_sessions.shape)), mode='raise')\n",
    "        \n",
    "    return diffs\n",
    "\n",
    "dts = compute_dwell_time(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEWCAYAAACt5MYgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFCxJREFUeJzt3Xu4ZXV93/H3Ry6igCAOTiiMM4CklWBE0YANkWnro+HS0jRpxKpAakRzafURS0YlT7HKU6OVJN7SyCUg8VKfJFaCsQ5azqBGIWC5qijiICIXkQjMhCgM3/6x1gl7Ts5lzzlnn31+h/frec4za6+19lrf31pnPvu3f2vvdVJVSJLa8IRxFyBJGp6hLUkNMbQlqSGGtiQ1xNCWpIYY2pLUEEN7jJL8zyS/u0jbekaSLUl26h9PJPn1xdj2lP1sSXLQlHlPSPKpJK9e7P0ttiSnJvniwONK8sx5bOcVSTYubnXS3AztEUmyOclDSR5M8qMkf53kdUn+4ZhX1euq6u1DbuvFs61TVd+tqj2qatti1D/LfvaoqlunzH4H8PmqOn++2x3meC2lJDf1L1BbkmxL8vcDj99SVR+pqpeMo7b5SrKuf5GabMfmJBumrHN0f+zvT3Jfki8lecHA8v2SnJ/kzv5cfSPJ25Ls3i9/e5IbkjyS5Kwp216f5NGB/W9JcsqSNH4F2XncBaxw/7qqPpdkL+AY4A+BI4FfW8ydJNm5qh5ZzG3uiKp6yyJtakmO1zCq6mcmp5NMAH9aVectdR0jsndVPZLk+cCmJNdU1WVJngJcCvwG8AlgV+AXgB8DJNkH+DLw18ALq2pzkjXAm4CDgeuBW4AzgNfNsO/vV9UBI2zbimdPewlU1f1VdQnwMuCUJIcBJLkwyTv66VVJLu17mfcl+UI/7HAx8AzgL/ueyRkDPaZXJ/ku8H8H5g2+EB+c5KokD/TDF/v0+1qf5HuDNQ725pPslOQtSb7d96au6f9zbjeckGSvJB9O8oMktyU5c7JnPDkMkeR/JPnbJN9Jcux8j1eSA/tjM7n9c5PcM1D/xUneMFDXZG/wjiTvSD9stFgy/TDLbyb5Vn/M3p7k4L7X+kCSTyTZdWD9E5Jcm8feVfzsLPv6Z0ku638vbk7yqwPLLkzygSSf7vd7ZZKDh2lDVV0N3AQc3s/66X7+x6pqW1U9VFUbq+r6fvkbgQeBV1bV5n7d26vq9ZPrVNVFVfWZfj2NgKG9hKrqKuB7dL2XqU7vl+0LrAbe0j2lXgV8l64XukdVvWvgOccAzwJeOsMuTwb+I7Af8Ajw3iFLfSPwcuA44Cn9Nv5umvXeB+wFHNTXcjLb94qPBG4GVgHvAs5PkiFr2O54VdV3gAeA5/aLXwRsSfKs/vExwKZ++kK69j6zX/8lwKKP70/jpcARwFF0vc0PAa8E1gCH0R1TkjwXuAB4LfA04I+BS5I8ceoG+2GHy4CPAk8HTgI+mOTQgdVOAt4GPJWup3v2MMUmOaqv65Z+1jeBbUkuSnJskqdOecqLgb+oqkeH2f4Mnp7k7v5F/Pcnh1U0PEN76X0f2Gea+Q/Thevaqnq4qr5Qc98Y5qyq2lpVD82w/OKqurGqtgK/C/zqkD3OXwfOrKqbq3NdVf1wcIV+OycBb66qB/ue13uAVw2sdltVnduPs1/Ut2/1EPsfNHi8NgHHJPmp/vGf9Y8PpHtxuS7JaroXmzf0x+Ye4Pf7WkftXVX1QFXdBNwIbKyqW6vqfuAzPPaCcxrwx1V1Zd+jvYhuCOKoabZ5ArC5qv6kqh6pqv8H/Dnw7wfW+WRVXdUPkX2Ex3rOM7k3yUN0Qx0fBP43QFU9ABwNFHAu8IMkl/THFLoXmDt34HhM9Y2+tv2Af0n3AnfOArb3uGRoL739gfummf9uuh7PxiS3ZsoFohncvgPLbwN2oev1zmUN8O051lnVb++2KfvYf+DxXZMTVTXZU99jiP0PGjxem4D1dL3sK4AJuh72McAX+h7g2r6uO/uhhx/R9WSfvoP7nY+7B6YfmubxZNvXAqdP1tfXuAb4J9Nscy1w5JR1XwH81MA6dw1M/x1zH+NV/Tqn0x3PXSYXVNXXq+rUftz5sL6mP+gX/5AucOelqu6qqq9V1aP9O6czgF+e7/YerwztJZTuKvz+wBenLut7q6dX1UHAvwHemORfTS6eYZNz9cTXDEw/g643fy+wFXjyQF070Q3LTLqd7sLSbO7tt7d2yj7umON5Q5vmeG2iG1pa309/Efh5th8auZ2u17qqqvbuf54yeGFxGbgdOHugvr2r6slV9bEZ1t00Zd09quo3FlJA38M/B/h74DdnWOcbdENNh/WzPgf8UhbvEz2FGbTDPGBLIMlTkpwAfJzuUwg3TLPOCUme2Y/53g9sAybHDu+mGzfeUa9McmiSJwP/Dfizfqjim8BuSY5PsgtwJjA4nnoe8PYkh6Tzs0meNrjhfjufAM5OsmeStXRj4X86jzq3M9Pxqqpv0fVYX0kXZA/QHZtfpg/tqroT2Ai8p9/OE/oLgscstK5FdC7wuiRH9sd39/5c7DnNupcCP53kVUl26X9eMDCWv1DvBM5Islt/wfP0JAcApLv4/HLgK/2659ANQ13Un2+S7J/knMkLqX19u9Fly879die/O/Avkqzt27ym3/enFqkdjxuG9mj9ZZIH6XpLb6X7pZ/p42uH0PVkttCPNVbV5f2y/w6c2b89ftMO7P9iup7SXcBuwH+G7tMZdL2r8+h6xlvpLvhNOocukDfSXfw7H3jSNNv/T/1zb6Xr9X6U7gLbfA1zvDYBP6yq2wceB/jqwDon031c7WvA39KNfc/7bf1i6z+18Rrg/XT13QKcOsO6D9JdSD2Jbnz/LuD32P5FdiE+3dfwGrpPfBwJXJlkK11Y30g3jEJV3Qf8c7p3WFf25+rzdJ2MyYuZ59K9sL6c7hw+xGPXOZ5L93HBrf2/N9D/Tmp48Y8gSFI77GlLUkMMbUlqiKEtSQ0xtCWpIYt+w6hVq1bVunXr5vXcrVu3svvuK+9brSuxXSuxTWC7WrOS2nXNNdfcW1X7zrXeoof2unXruPrqq+f13ImJCdavX7+4BS0DK7FdK7FNYLtas5LaleS2uddyeESSmmJoS1JDDG1JaoihLUkNMbQlqSGGtiQ1xNCWpIYY2pLUEENbkhpiaEtSQwxtSWqIoS1JDTG0JakhhrYkNcTQlqSGGNqS1BBDW5IaYmhLUkMMbUlqiKEtSQ0xtCWpIYa2JDXE0JakhhjaktQQQ1uSGmJoS1JDDG1JaoihLUkNMbQlqSGGtiQ1xNCWpIYY2pLUEENbkhpiaEtSQwxtSWqIoS1JDTG0JakhhrYkNcTQlqSGGNqS1BBDW5IaYmhLUkMMbUlqiKEtSQ0xtCWpIYa2JDXE0JakhhjaktQQQ1uSGmJoS1JDDG1JaoihLUkNMbQlqSGGtiQ1xNCWpIYY2pLUEENbkhpiaEtSQwxtSWqIoS1JDTG0JakhhrYkNcTQlqSGGNqS1BBDW5IaYmhLUkMMbUlqiKEtSQ0xtCWpIYa2JDXE0JakhhjaktQQQ1uSGmJoS1JDDG1JaoihLUkNMbQlqSGGtiQ1xNCWpIYY2pLUEENbkhpiaEtSQwxtSWqIoS1JDTG0JakhhrYkNcTQlqSGGNqS1BBDW5IaYmhLUkMMbUlqyM7jLmDcnvO2jdz/0MOj39H/+fSsi/d81gYe/Po7R1/HYpqjTaO215N24br/+pKx1iAttcd9aN//0MNsfufxI93HxMQE69evn3WdZ1+0YeR1LKZh2jRq6zaM90VDGgeHRySpIYa2JDXE0JakhhjaktQQQ1uSGmJoS1JDll1oJxl3CZI0L0uRX8sutCVJMzO0JakhhrYkNcTQlqSGDBXaSX4xyc1JbkmyYdRFSZKmN2doJ9kJ+ABwLHAo8PIkh466MEnSPzZMT/vngFuq6taq+gnwceDE0ZYlSZrOMLdm3R+4feDx94AjB1dIchpwGsDq1auZmJiYVzFbtmwBlv6Wm/Otd1hbtmwZah+jrmMxDdumURvJ78qY7xM+MrZrSYz8/0VVzfoD/Apw3sDjVwHvn2n9I444oubr8ssvr66kpbP2dy4d+T4uv/zyOdc57MLDRl7HYhqmTaM2inO3HNo1CrZraSwkv4Cra448rqqhhkfuANYMPD6gnydJWmLDhPbfAIckOTDJrsBJwCWjLUuSNJ05x7Sr6pEkvw18FtgJuKCqbhp5ZZKkf2SovxFZVX8F/NWIa5EkzcFvREpSQwxtSWqIoS1JDVl2od19XFGS2rMU+bXsQluSNDNDW5IaYmhLUkMMbUlqiKEtSQ0xtCWpIUN9jX2lW5L7d89xz989n7X09xFfsDHfx3ivJ+0y1v1L4/C4D+3N7zx+5PuYmJhg/fr1c6w1+joW03BtkrTYHB6RpIYY2pLUEENbkhpiaEtSQwxtSWqIoS1JDTG0JakhhrYkNcTQlqSGGNqS1BBDW5IaYmhLUkMMbUlqiKEtSQ0xtCWpIYa2JDXE0JakhhjaktQQQ1uSGmJoS1JDDG1JaoihLUkNMbQlqSGGtiQ1xNCWpIYY2pLUEENbkhpiaEtSQwxtSWqIoS1JDTG0JakhhrYkNcTQlqSGGNqS1BBDW5IaYmhLUkMMbUlqiKEtSQ0xtCWpIYa2JDXE0JakhhjaktQQQ1uSGmJoS1JDDG1JaoihLUkNMbQlqSGGtiQ1xNCWpIYY2pLUEENbkhpiaEtSQwxtSWqIoS1JDTG0JakhhrYkNcTQlqSGGNqS1BBDW5IaYmhLUkMMbUlqiKEtSQ0xtCWpIYa2JDXE0JakhhjaktQQQ1uSGmJoS1JDDG1JaoihLUkNMbQlqSGGtiQ1xNCWpIYY2pLUEENbkhpiaEtSQwxtSWqIoS1JDTG0JakhhrYkNcTQlqSGGNqS1BBDW5IaYmhLUkMMbUlqiKEtSQ0xtCWpIYa2JDXE0JakhhjaktQQQ1uSGpKqWtwNJj8Abpvn01cB9y5iOcvFSmzXSmwT2K7WrKR2ra2qfedaadFDeyGSXF1Vzx93HYttJbZrJbYJbFdrVmq7ZuPwiCQ1xNCWpIYst9D+0LgLGJGV2K6V2CawXa1Zqe2a0bIa05YkzW659bQlSbMwtCWpIcsitJP8YpKbk9ySZMO461mIJJuT3JDk2iRX9/P2SXJZkm/1/z513HXOJckFSe5JcuPAvGnbkc57+/N3fZLnja/y2c3QrrOS3NGfs2uTHDew7M19u25O8tLxVD23JGuSXJ7ka0luSvL6fn6z52yWNjV/vhakqsb6A+wEfBs4CNgVuA44dNx1LaA9m4FVU+a9C9jQT28Afm/cdQ7RjhcBzwNunKsdwHHAZ4AARwFXjrv+HWzXWcCbpln30P738YnAgf3v6U7jbsMM7doPeF4/vSfwzb7+Zs/ZLG1q/nwt5Gc59LR/Drilqm6tqp8AHwdOHHNNi+1E4KJ++iLg346xlqFU1RXAfVNmz9SOE4EPV+crwN5J9luaSnfMDO2ayYnAx6vqx1X1HeAWut/XZaeq7qyqr/bTDwJfB/an4XM2S5tm0sz5WojlENr7A7cPPP4es5+Y5a6AjUmuSXJaP291Vd3ZT98FrB5PaQs2UztWwjn87X6Y4IKB4asm25VkHfBc4EpWyDmb0iZYQedrRy2H0F5pjq6q5wHHAr+V5EWDC6t7H9f85yxXSjt6fwQcDBwO3Am8Z7zlzF+SPYA/B95QVQ8MLmv1nE3TphVzvuZjOYT2HcCagccH9POaVFV39P/eA3yS7u3Z3ZNvPft/7xlfhQsyUzuaPodVdXdVbauqR4FzeewtdVPtSrILXbh9pKr+op/d9Dmbrk0r5XzN13II7b8BDklyYJJdgZOAS8Zc07wk2T3JnpPTwEuAG+nac0q/2inAp8ZT4YLN1I5LgJP7TyQcBdw/8JZ82ZsylvtLdOcMunadlOSJSQ4EDgGuWur6hpEkwPnA16vqnIFFzZ6zmdq0Es7Xgoz7Smj3jo3j6K4Mfxt467jrWUA7DqK7en0dcNNkW4CnAZ8HvgV8Dthn3LUO0ZaP0b31fJhubPDVM7WD7hMIH+jP3w3A88dd/w626+K+7uvp/uPvN7D+W/t23QwcO+76Z2nX0XRDH9cD1/Y/x7V8zmZpU/PnayE/fo1dkhqyHIZHJElDMrQlqSGGtiQ1xNCWpIYY2pLUEENby06St/Z3dbu+v4vbkWOqY8s49ivNZudxFyANSvJC4AS6u7v9OMkqurs/SsKetpaf/YB7q+rHAFV1b1V9P8kRSTb1N+L67MBXs18w0CN/9+R9spOcmuT9kxtNcmmS9f30liRnJ7kuyVeSrO7nH5jky+nuh/6Ogedmctv9spf18/dLckW/7xuT/MJSHSQ9fhnaWm42AmuSfDPJB5Mc099/4n3Ar1TVEcAFwNn9+n8CvLaqDge2DbmP3YGvVNVzgCuA1/Tz/xD4o6p6Nt23Jif9O7qbEz0HeDHw7v5F4z8An+33/Ry6b+xJI2Voa1mpqi3AEcBpwA+A/wW8FjgMuCzJtcCZwAFJ9gb2rKov90//6JC7+QlwaT99DbCun/55uq+5Q/dV6UlHAx+r7iZFdwObgBfQ3Tfn15KcBTy7uns+SyPlmLaWnaraBkwAE0luAH4LuKmqXji4Xh/aM3mE7Tsluw1MP1yP3b9hG9v/Pxj6vg5VdUV/693jgQuTnFNVHx72+dJ82NPWspLknyY5ZGDW4XR/sWTf/iIlSXZJ8jNV9SPgwYFPl5w08LzNwOFJnpBkDcP9BZMvDWzjFQPzvwC8LMlOSfal+5NlVyVZC9xdVecC59H9GTNppOxpa7nZA3hf34t+hO5PRp0GfAh4b5K96H5v/4DuToqvBs5N8ijdsMX9/Xa+BHwH+Bpd6H91iH2/Hvhokt9h+9vnfhJ4Id3dGws4o6ruSnIK8F+SPAxsAU6ed6ulIXmXPzUtyR79ODhJNtDdpvP1Yy5LGhl72mrd8UneTPe7fBtw6njLkUbLnrYkNcQLkZLUEENbkhpiaEtSQwxtSWqIoS1JDfn/inJskMueBCkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get paper statistics\n",
    "def get_statistics(dts):\n",
    "    filtered = np.array(list(filter(lambda x: int(x) != 0, dts)))\n",
    "    pd_dts = pd.DataFrame(filtered)\n",
    "    pd_dts.boxplot(vert=False, showfliers=False) # no outliers in boxplot\n",
    "    plt.xlabel(\"Segundos\")\n",
    "    plt.title(\"DistribuciÃ³n Dwell Time en RSC15\")\n",
    "    plt.savefig(\"./DwellTime.pdf\", format=\"pdf\")#show()\n",
    "    pd_dts.describe()\n",
    "    \n",
    "get_statistics(dts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    58233.000000\n",
       "mean       123.458726\n",
       "std        322.402707\n",
       "min          0.000000\n",
       "25%          3.162000\n",
       "50%         39.464000\n",
       "75%         99.597000\n",
       "max       3598.143000\n",
       "Name: Time, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def join_dwell_reps(df, dt, threshold=75):\n",
    "    # Calculate d_ti/threshold + 1\n",
    "    # then add column to dataFrame\n",
    "    \n",
    "    dt //= threshold\n",
    "    dt += 1   \n",
    "    df['DwellReps'] = pd.Series(dt.astype(np.int64), index=dt.index)\n",
    "    #return df\n",
    "\n",
    "join_dwell_reps(new_df, dts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SessionId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Time</th>\n",
       "      <th>ItemIdx</th>\n",
       "      <th>DwellReps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30016</th>\n",
       "      <td>11255604</td>\n",
       "      <td>214859075</td>\n",
       "      <td>1.411909e+09</td>\n",
       "      <td>281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22507</th>\n",
       "      <td>11255604</td>\n",
       "      <td>214859876</td>\n",
       "      <td>1.411909e+09</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42161</th>\n",
       "      <td>11255652</td>\n",
       "      <td>214853657</td>\n",
       "      <td>1.411909e+09</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42630</th>\n",
       "      <td>11255652</td>\n",
       "      <td>214676486</td>\n",
       "      <td>1.411909e+09</td>\n",
       "      <td>1053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>11255668</td>\n",
       "      <td>214857570</td>\n",
       "      <td>1.411907e+09</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>11255668</td>\n",
       "      <td>214857568</td>\n",
       "      <td>1.411907e+09</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20259</th>\n",
       "      <td>11255679</td>\n",
       "      <td>214839950</td>\n",
       "      <td>1.411921e+09</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8564</th>\n",
       "      <td>11255679</td>\n",
       "      <td>214848995</td>\n",
       "      <td>1.411921e+09</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37639</th>\n",
       "      <td>11255679</td>\n",
       "      <td>214829724</td>\n",
       "      <td>1.411921e+09</td>\n",
       "      <td>617</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37879</th>\n",
       "      <td>11255679</td>\n",
       "      <td>214856981</td>\n",
       "      <td>1.411921e+09</td>\n",
       "      <td>623</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SessionId     ItemId          Time  ItemIdx  DwellReps\n",
       "30016   11255604  214859075  1.411909e+09      281          1\n",
       "22507   11255604  214859876  1.411909e+09      146          1\n",
       "42161   11255652  214853657  1.411909e+09     1005          1\n",
       "42630   11255652  214676486  1.411909e+09     1053          1\n",
       "1544    11255668  214857570  1.411907e+09        8          1\n",
       "3989    11255668  214857568  1.411907e+09       12          1\n",
       "20259   11255679  214839950  1.411921e+09      105          1\n",
       "8564    11255679  214848995  1.411921e+09       28          1\n",
       "37639   11255679  214829724  1.411921e+09      617          2\n",
       "37879   11255679  214856981  1.411921e+09      623          3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58233, 5)\n"
     ]
    }
   ],
   "source": [
    "# Now, we augment the sessions copying each entry an \n",
    "# additional (dwellReps[i]-1) times\n",
    "\n",
    "def augment_old(df):\n",
    "    col_names = list(df.columns.values)\n",
    "    augmented  = pd.DataFrame(columns = col_names)\n",
    "    \n",
    "    pbar = tqdm(total=len(df['SessionId'].unique()))\n",
    "    \n",
    "    for row in df.iterrows():\n",
    "        for rep in range(int(row[1]['DwellReps'])):\n",
    "            augmented = augmented.append(row[1])#Df, ignore_index=True)\n",
    "        pbar.update(1)\n",
    "        \n",
    "    pbar.close()\n",
    "            \n",
    "    return augmented\n",
    "\n",
    "def augment(df):    \n",
    "    col_names = list(df.columns.values)[:3]\n",
    "    print(col_names)\n",
    "    augmented = np.repeat(df.values, df['DwellReps'], axis=0) \n",
    "    print(augmented[0][:3])  \n",
    "    augmented = pd.DataFrame(data=augmented[:,:3],\n",
    "                             columns=col_names)\n",
    "    \n",
    "    dtype = {'SessionId': np.int64, \n",
    "             'ItemId': np.int64, \n",
    "             'Time': np.float32}\n",
    "    \n",
    "    for k, v in dtype.items():\n",
    "        augmented[k] = augmented[k].astype(v)\n",
    "                             \n",
    "    \n",
    "    return augmented\n",
    "\n",
    "#df_aug = augment(new_df)\n",
    " \n",
    "df_aug = new_df    \n",
    "print(df_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58233, 5)\n",
      "       SessionId     ItemId          Time  ItemIdx  DwellReps\n",
      "30016   11255604  214859075  1.411909e+09      281          1\n",
      "22507   11255604  214859876  1.411909e+09      146          1\n",
      "42161   11255652  214853657  1.411909e+09     1005          1\n",
      "42630   11255652  214676486  1.411909e+09     1053          1\n",
      "1544    11255668  214857570  1.411907e+09        8          1\n",
      "3989    11255668  214857568  1.411907e+09       12          1\n",
      "20259   11255679  214839950  1.411921e+09      105          1\n",
      "8564    11255679  214848995  1.411921e+09       28          1\n",
      "37639   11255679  214829724  1.411921e+09      617          2\n",
      "37879   11255679  214856981  1.411921e+09      623          3\n",
      "32336   11255679  214857596  1.411921e+09      337          1\n",
      "6378    11255679  214819412  1.411921e+09       18          1\n",
      "39022   11255679  214854810  1.411921e+09      708          1\n",
      "1541    11255714  214857570  1.411944e+09        8          2\n",
      "3986    11255714  214857568  1.411944e+09       12          5\n",
      "3987    11255714  214857568  1.411944e+09       12          4\n",
      "26052   11255714  214859908  1.411945e+09      191          4\n",
      "42574   11255714  214865117  1.411945e+09     1045          1\n",
      "21035   11255729  214854872  1.411905e+09      115         22\n",
      "42619   11255729  214864841  1.411906e+09     1046          1\n"
     ]
    }
   ],
   "source": [
    "print(df_aug.shape)\n",
    "print(df_aug[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_aug.to_pickle(\"./augmented.pkl\")\n",
    "df_aug.to_csv(\"./augmented.csv\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3kJRW-qQ17_Q",
    "outputId": "1e336f48-43aa-4929-cefd-63e02dee3449",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import math\n",
    "import sklearn\n",
    "import psutil\n",
    "import humanize\n",
    "import GPUtil as GPU\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import cosine_proximity, categorical_crossentropy\n",
    "from keras.models import Model, Sequential\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Input, Dense, Dropout, CuDNNGRU, Embedding, concatenate, Lambda, multiply\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFkivhjnvrKO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(data, batch_size=128, session_max_len=19, fraction=1, offset=0, embedding=True, n_items=None, itemids=None, itemidmap=None, aug = True):\n",
    "    item_key = 'ItemId'\n",
    "    session_key = 'SessionId'\n",
    "    time_key = 'Time'\n",
    "    \n",
    "    data = pd.merge(data, pd.DataFrame({item_key:itemids, 'ItemIdx':itemidmap[itemids].values}), on=item_key, how='inner') # agrego esa columna\n",
    "    \n",
    "    #print(\"Cantidad de samples: {}\".format(len(data)//fraction))\n",
    "\n",
    "    data.sort_values([session_key, time_key], inplace=True) # ordenamos por sesion\n",
    "\n",
    "    #data.sort_values([time_key], inplace=True)\n",
    "    length = len(data['ItemId'])\n",
    "    #data = data[length-length//fraction:]\n",
    "    \n",
    "    offset_sessions = np.zeros(data[session_key].nunique()+1, dtype=np.int32)\n",
    "    offset_sessions[1:] = data.groupby(session_key).size().cumsum() # arreglo con offset acumulativo de inicio de cada sesion\n",
    "    #offset_sessions = offset_sessions[length-length//fraction:]\n",
    "    \n",
    "    actual_session = 0 + offset\n",
    "    \n",
    "    batch_feats = None\n",
    "    batch_labels = None\n",
    "    # GRU_LAYER.reset_states() si usamos session parallel\n",
    "\n",
    "    while True:\n",
    "      datum = data[offset_sessions[actual_session]:offset_sessions[actual_session+1]][item_key]  # aqui toda la info de la sesion\n",
    "      datum = datum.values.reshape(-1,1)           \n",
    "      for i in range(offset_sessions[actual_session+1]-offset_sessions[actual_session]-1):\n",
    "        if not aug:\n",
    "          if (i != offset_sessions[actual_session+1]-offset_sessions[actual_session]-2):\n",
    "            continue\n",
    "        feats = datum[0:i+1]\n",
    "   \n",
    "        if feats.shape[0] > session_max_len:\n",
    "            feats = feats[:session_max_len] # aca cambiar a mas nuevos\n",
    "        else:\n",
    "            feats = np.append(np.zeros((session_max_len-feats.shape[0],1), dtype=np.int8), feats) # left pad with zeros\n",
    "\n",
    "        feats = feats.reshape(1,-1) # (1, 19)\n",
    "\n",
    "        label = datum[i+1]\n",
    "        label = np.expand_dims(label, axis=0)  # Termina siendo (1, dimn_previa)\n",
    "\n",
    "\n",
    "        if not isinstance(batch_feats, type(feats)):\n",
    "            batch_feats = feats\n",
    "        else:\n",
    "            batch_feats = np.append(batch_feats, feats, axis=0)\n",
    "\n",
    "        if not isinstance(batch_labels, type(label)):\n",
    "            batch_labels = label\n",
    "        else:\n",
    "            batch_labels = np.append(batch_labels, label, axis=0)\n",
    "\n",
    "        #print(batch_feats)\n",
    "        #print(batch_labels)\n",
    "        \n",
    "        if batch_labels.shape[0] == batch_size:\n",
    "          if not embedding:\n",
    "            # batch_labels.shape = (batch_size, 1)\n",
    "            #new_labels = np.zeros((batch_size, n_items))\n",
    "            #new_labels[0][:] = to_categorical(itemidmap[label[0][0]], num_classes=n_items)\n",
    "            batch_labels = to_categorical(itemidmap[batch_labels.flatten()], num_classes=n_items)\n",
    "          #print(\"Yielding batch with shape {} train, {} target\".format(batch_feats.shape, batch_labels.shape))\n",
    "            pass\n",
    "          \n",
    "          yield batch_feats, batch_labels\n",
    "          # resume batch generation\n",
    "          batch_feats = None\n",
    "          batch_labels = None\n",
    "\n",
    "    # TODO: Dropout random como en el paper\n",
    "\n",
    "      actual_session = (actual_session + 1) % len(offset_sessions)\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "eQslL5CpRjdQ",
    "outputId": "bd8d7ef2-638d-42a1-eaf5-6e96636a7be7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512 #como en el paper\n",
    "session_max_len = 19\n",
    "embeddingp=False\n",
    "\n",
    "n_items = len(train_data['ItemId'].unique())+1\n",
    "print(\"Items unicos training:\", n_items)\n",
    "\n",
    "dev_n_items = len(dev_data['ItemId'].unique())+1\n",
    "print(\"Items unicos dev:\", dev_n_items)\n",
    "\n",
    "test_n_items = len(test_data['ItemId'].unique())+1\n",
    "print(\"Items unicos testing:\", test_n_items)\n",
    "\n",
    "train_samples_qty = len(train_data['SessionId'].unique()) # cantidad sesiones no augmentadas de train\n",
    "print(\"Sesiones training:\", train_samples_qty)\n",
    "\n",
    "dev_samples_qty = len(dev_data['SessionId'].unique()) # cantidad sesiones no augmentadas de dev\n",
    "print(\"Sesiones validation:\",dev_samples_qty)\n",
    "\n",
    "test_samples_qty = len(test_data['SessionId'].unique()) # cantidad sesiones no augmentadas de test\n",
    "print(\"Sesiones testing:\", test_samples_qty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1i_adI_ASgDi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_fraction = 1#256 # 1/fraction es la cantidad de sesiones mas recientes a considerar\n",
    "dev_fraction = 1#2\n",
    "\n",
    "train_offset_step=35000#40000#15530\n",
    "dev_offset_step=65#240\n",
    "\n",
    "\n",
    "aux = [0]\n",
    "aux.extend(list(train_data['ItemId'].unique()))\n",
    "itemids = np.array(aux)\n",
    "itemidmap = pd.Series(data=np.arange(n_items), index=itemids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5z1JvtX8qV0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_generator = next(batch_generator(test_data, \n",
    "                                batch_size=batch_size, \n",
    "                                fraction=train_fraction, \n",
    "                                offset=3,\n",
    "                               embedding=False,\n",
    "                                n_items=n_items,\n",
    "                               itemids=itemids,\n",
    "                               itemidmap=itemidmap,\n",
    "                                aug = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "O5_sa72xSF50",
    "outputId": "b1a69ec9-6e86-44ba-d19e-69fe1f59cf57",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modelo\n",
    "\n",
    "# ToDo:\n",
    "# meterle self-attention (hay implementaciones en Keras)\n",
    "\n",
    "def custom_cosine_loss(itemidmap, n_items):\n",
    "    #emb = model.layers[1]\n",
    "    emb = itemidmap\n",
    "    nu_items = n_items\n",
    "    # y_pred ya viene con embedding, y_true solo como one-hot\n",
    "    def fn(y_true, y_pred):\n",
    "        #print(y_true.shape, y_pred.shape)\n",
    "        y_pred_emb = to_categorical(emb[y_pred], num_classes=nu_items)\n",
    "        #print(y_true_emb)\n",
    "        #y_pred_emb = emb.call(y_pred)\n",
    "\n",
    "    #y_true_emb = np.array([y_true], dtype='int32')\n",
    "    #y_true_emb = tf.convert_to_tensor(y_true_emb)\n",
    "    #y_true_emb = model.layers[0].call(y_true)\n",
    "    #y_true_emb = K.get_value(y_true_emb)[0][0] # 50,\n",
    "\n",
    "        return 1 - cosine_proximity(y_true, y_pred_emb)\n",
    "        #return cosine_proximity(y_true_emb, y_pred_emb)\n",
    "    return fn\n",
    "    \n",
    "emb_size = 50\n",
    "size = emb_size\n",
    "#size = emb_size if embeddingp else n_items\n",
    "\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "emb = Embedding(n_items, emb_size, embeddings_initializer='uniform', input_length=19)\n",
    "model.add(emb)\n",
    "model.add(Dropout(0.25))\n",
    "model.add(CuDNNGRU(1000)) \n",
    "model.add(Dropout(0.25))\n",
    "if embeddingp:\n",
    "    model.add(Dense(emb_size, activation='softmax'))\n",
    "    custom_loss = custom_cosine_loss(emb)  ## DUDA: Esta usando los pesos actuales?\n",
    "    model.compile(loss=custom_loss, optimizer='adam')\n",
    "else:\n",
    "    model.add(Dense(n_items, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()\n",
    "\"\"\"\n",
    "\n",
    "inputs = Input(shape=(19,))\n",
    "emb = Embedding(n_items, emb_size, embeddings_initializer='uniform', input_length=19)(inputs)\n",
    "drop1 = Dropout(0.25)(emb)\n",
    "gru = CuDNNGRU(1000)(drop1)\n",
    "drop2 = Dropout(0.25)(gru)\n",
    "predictions = Dense(n_items, activation='softmax')(drop2)\n",
    "model = Model(input=inputs, output=[predictions])\n",
    "custom_loss = custom_cosine_loss(itemidmap, n_items)\n",
    "opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "# Try Nadam, too\n",
    "model.compile(loss=categorical_crossentropy, optimizer=opt)\n",
    "model.summary()\n",
    "\n",
    "filepath='./bast/model_checkpoint'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=2, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "1XFQrjF7TZlU",
    "outputId": "9c209770-d67a-4bb3-a0ac-ed2a2a65fc0e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "real_epoca = 1\n",
    "for epoch in range(1):\n",
    "    filepath='./bast/model_{}'.format(real_epoca)\n",
    "    model.load_weights('./bast/model_{}'.format(real_epoca-1))\n",
    "    #model.save_weights(filepath)\n",
    "    train_generator = batch_generator(train_data, \n",
    "                                      batch_size=batch_size, \n",
    "                                      fraction=train_fraction, \n",
    "                                      offset=train_offset_step*epoch,\n",
    "                                     embedding=embeddingp,\n",
    "                                      n_items=n_items,\n",
    "                                     itemids=itemids,\n",
    "                                     itemidmap=itemidmap)\n",
    "    \n",
    "    dev_generator = batch_generator(dev_data, \n",
    "                                    batch_size=batch_size, \n",
    "                                    fraction=dev_fraction, \n",
    "                                    offset=dev_offset_step*epoch,\n",
    "                                    embedding=embeddingp,\n",
    "                                    n_items=n_items,\n",
    "                                    itemids=itemids,\n",
    "                                     itemidmap=itemidmap)\n",
    "    \n",
    "    history = model.fit_generator(train_generator,\n",
    "                                steps_per_epoch=train_offset_step,#15530,\n",
    "                                epochs=1,\n",
    "                                validation_data=dev_generator,\n",
    "                                validation_steps=dev_offset_step,#105,\n",
    "                                callbacks=callbacks_list)\n",
    "    \n",
    "    model.save_weights(filepath)\n",
    "    \n",
    "    weights = model.layers[1].get_weights()[0]\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    nbrs = NearestNeighbors(n_neighbors=20, algorithm='ball_tree').fit(weights)\n",
    "    distances, indices = nbrs.kneighbors(weights) # Vienen ya ordenados! # Shape (37484, 20)\n",
    "    # Paso 3: Dado un vector embedding arbitrario, obtener el item mÃ¡s cercano a Ã©ste. Aplicarla sobre los 20 anteriores.\n",
    "    from sklearn.metrics import recall_score\n",
    "\n",
    "    test_generator = batch_generator(test_data, \n",
    "                                      batch_size=batch_size, \n",
    "                                      fraction=train_fraction, \n",
    "                                      offset=0,\n",
    "                                     embedding=embeddingp,\n",
    "                                      n_items=n_items,\n",
    "                                     itemids=itemids,\n",
    "                                     itemidmap=itemidmap)\n",
    "\n",
    "\n",
    "    n = 0\n",
    "    suma = 0\n",
    "    while True:\n",
    "          try:\n",
    "            test_batch = next(test_generator)\n",
    "            pred = model.predict(test_batch[0]) # batch_size, n_items => 512, 37484\n",
    "            label = test_batch[1]               \n",
    "\n",
    "            #print(pred.shape)\n",
    "            #print(label.shape) \n",
    "\n",
    "            for row_idx in range(test_batch[0].shape[0]):\n",
    "              pred_row = pred[row_idx] # 37484, #.reshape(1, -1) # 50,\n",
    "              label_row = label[row_idx]        #.reshape(1, -1) # 50,\n",
    "\n",
    "              #print(pred_row.shape)\n",
    "              #print(label_row.shape)\n",
    "\n",
    "              idx1 = pred_row.argsort()[-20:][::-1]\n",
    "              idx2 = label_row.argsort()[-1:][::-1]\n",
    "\n",
    "              n += 1\n",
    "              #print(idx1)\n",
    "              #print(idx2)\n",
    "              if idx2[0] in idx1:\n",
    "                suma += 1\n",
    "\n",
    "          except:\n",
    "            break\n",
    "    print(\"Recall epoch {}: {}\".format(epoch, suma/n))\n",
    "    real_epoca += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath='./bast/model_{}'.format(epoch)\n",
    "model.save_weights(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Started @ 9.2\n",
    "\n",
    "En 8.01 se puso lento... ojo\n",
    "\n",
    "Goin up 7.8464\n",
    "\n",
    "Epoch time: 2:00 aprox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = model.layers[1].get_weights()[0]\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=20, algorithm='ball_tree').fit(weights)\n",
    "distances, indices = nbrs.kneighbors(weights) # Vienen ya ordenados! # Shape (37484, 20)\n",
    "# Paso 3: Dado un vector embedding arbitrario, obtener el item mÃ¡s cercano a Ã©ste. Aplicarla sobre los 20 anteriores.\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "test_generator = batch_generator(test_data, \n",
    "                                  batch_size=batch_size, \n",
    "                                  fraction=train_fraction, \n",
    "                                  offset=0,\n",
    "                                 embedding=embeddingp,\n",
    "                                  n_items=n_items,\n",
    "                                 itemids=itemids,\n",
    "                                 itemidmap=itemidmap)\n",
    "\n",
    "\n",
    "n = 0\n",
    "suma = 0\n",
    "while True:\n",
    "  try:\n",
    "    test_batch = next(test_generator)\n",
    "    pred = model.predict(test_batch[0]) # batch_size, n_items => 512, 37484\n",
    "    label = test_batch[1]               \n",
    "\n",
    "    #print(pred.shape)\n",
    "    #print(label.shape) \n",
    "\n",
    "    for row_idx in range(test_batch[0].shape[0]):\n",
    "      pred_row = pred[row_idx] # 37484, #.reshape(1, -1) # 50,\n",
    "      label_row = label[row_idx]        #.reshape(1, -1) # 50,\n",
    "\n",
    "      #print(pred_row.shape)\n",
    "      #print(label_row.shape)\n",
    "\n",
    "      idx1 = pred_row.argsort()[-20:][::-1]\n",
    "      idx2 = label_row.argsort()[-1:][::-1]\n",
    "\n",
    "      n += 1\n",
    "      #print(idx1)\n",
    "      #print(idx2)\n",
    "      if idx2[0] in idx1:\n",
    "        suma += 1\n",
    "\n",
    "  except:\n",
    "    break\n",
    "print(\"Recall epoch {}: {}\".format(epoch, suma/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall epoch 0: 0.0005554759174311927 # seste se disparo y lo corte\n",
    "\n",
    "Recall epoch 0: 0.009550602064220183 # primera con lr mas bajo\n",
    "Recall epoch 1: 0.009084719036697247\n",
    "\n",
    "# TODO\n",
    "\n",
    "## Batcher solo entrega una sesion a la vez, si no se pierde independencia"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IIC3633_M1_Colab_V2.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
