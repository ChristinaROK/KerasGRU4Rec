{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhMT2zYloMpm"
   },
   "source": [
    "#**Proyecto - Sistemas Recomendadores - IIC3633**\n",
    "\n",
    "## Implementación de Dwell Time en GRU4REC\n",
    "\n",
    "\n",
    "Preliminar: Configuración entorno GPUs, Google Drive, entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfW00EfwSNQ6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load RSC15 preprocessed train dataframe\n",
    "PATH_TO_TRAIN = '../processedData/rsc15_train_tr.txt'\n",
    "train_data = pd.read_csv(PATH_TO_TRAIN, sep='\\t', dtype={'ItemId':np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_df(df):    \n",
    "    \n",
    "    n_items = len(train_data['ItemId'].unique())\n",
    "    aux = list(train_data['ItemId'].unique())\n",
    "    itemids = np.array(aux)\n",
    "    itemidmap = pd.Series(data=np.arange(n_items), index=itemids)  # (id_item => (0, n_items))\n",
    "    \n",
    "    item_key = 'ItemId'\n",
    "    session_key = 'SessionId'\n",
    "    time_key = 'Time'\n",
    "    \n",
    "    data = pd.merge(df, pd.DataFrame({item_key:itemids, 'ItemIdx':itemidmap[itemids].values}), on=item_key, how='inner')\n",
    "    data.sort_values([session_key, time_key], inplace=True)\n",
    "\n",
    "    length = len(data['ItemId'])\n",
    "        \n",
    "    return data\n",
    "    \n",
    "    \n",
    "new_df = preprocess_df(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_dwell_time(df):\n",
    "   \n",
    "    times_t = np.roll(df['Time'], -1) # Take time row\n",
    "    times_dt  = df['Time']            # Copy, then displace by one\n",
    "    \n",
    "    diffs = np.subtract(times_t, times_dt) # Take the pairwise difference\n",
    "    \n",
    "    length = len(df['ItemId'])\n",
    "    \n",
    "    # cummulative offset start for each session\n",
    "    offset_sessions = np.zeros(df['SessionId'].nunique()+1, dtype=np.int32)\n",
    "    offset_sessions[1:] = df.groupby('SessionId').size().cumsum() \n",
    "    \n",
    "    offset_sessions = offset_sessions - 1\n",
    "    offset_sessions = np.roll(offset_sessions, -1)\n",
    "    \n",
    "    # session transition implies zero-dwell-time\n",
    "    # note: paper statistics do not consider null entries, \n",
    "    # though they are still checked when augmenting\n",
    "    np.put(diffs, offset_sessions, np.zeros((offset_sessions.shape)), mode='raise')\n",
    "        \n",
    "    return diffs\n",
    "\n",
    "dts = compute_dwell_time(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get paper statistics\n",
    "def get_statistics(dts):\n",
    "    filtered = np.array(list(filter(lambda x: int(x) != 0, dts)))\n",
    "    pd_dts = pd.DataFrame(filtered)\n",
    "    pd_dts.boxplot(vert=False, showfliers=False) # no outliers in boxplot\n",
    "    plt.xlabel(\"Segundos\")\n",
    "    plt.title(\"Distribución Dwell Time en RSC15\")\n",
    "    plt.savefig(\"./DwellTime.pdf\", format=\"pdf\")#show()\n",
    "    pd_dts.describe()\n",
    "    \n",
    "get_statistics(dts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def join_dwell_reps(df, dt, threshold=75):\n",
    "    # Calculate d_ti/threshold + 1\n",
    "    # then add column to dataFrame\n",
    "    \n",
    "    dt //= threshold\n",
    "    dt += 1   \n",
    "    df['DwellReps'] = pd.Series(dt.astype(np.int64), index=dt.index)\n",
    "    #return df\n",
    "\n",
    "join_dwell_reps(new_df, dts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SessionId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Time</th>\n",
       "      <th>ItemIdx</th>\n",
       "      <th>DwellReps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>214536502</td>\n",
       "      <td>1.396879e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>1</td>\n",
       "      <td>214536500</td>\n",
       "      <td>1.396879e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>1</td>\n",
       "      <td>214536506</td>\n",
       "      <td>1.396879e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>1</td>\n",
       "      <td>214577561</td>\n",
       "      <td>1.396879e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>2</td>\n",
       "      <td>214662742</td>\n",
       "      <td>1.396890e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>2</td>\n",
       "      <td>214662742</td>\n",
       "      <td>1.396890e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6328</th>\n",
       "      <td>2</td>\n",
       "      <td>214825110</td>\n",
       "      <td>1.396890e+09</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6803</th>\n",
       "      <td>2</td>\n",
       "      <td>214757390</td>\n",
       "      <td>1.396890e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7752</th>\n",
       "      <td>2</td>\n",
       "      <td>214757407</td>\n",
       "      <td>1.396890e+09</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>2</td>\n",
       "      <td>214551617</td>\n",
       "      <td>1.396890e+09</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SessionId     ItemId          Time  ItemIdx  DwellReps\n",
       "0             1  214536502  1.396879e+09        0          3\n",
       "1770          1  214536500  1.396879e+09        1          1\n",
       "2312          1  214536506  1.396879e+09        2          2\n",
       "2381          1  214577561  1.396879e+09        3          1\n",
       "2519          2  214662742  1.396890e+09        4          1\n",
       "2520          2  214662742  1.396890e+09        4          2\n",
       "6328          2  214825110  1.396890e+09        5          1\n",
       "6803          2  214757390  1.396890e+09        6          1\n",
       "7752          2  214757407  1.396890e+09        7          2\n",
       "8119          2  214551617  1.396890e+09        8          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SessionId', 'ItemId', 'Time']\n",
      "[1.00000000e+00 2.14536502e+08 1.39687867e+09]\n",
      "(68052530, 3)\n"
     ]
    }
   ],
   "source": [
    "# Now, we augment the sessions copying each entry an \n",
    "# additional (dwellReps[i]-1) times\n",
    "\n",
    "def augment_old(df):\n",
    "    col_names = list(df.columns.values)\n",
    "    augmented  = pd.DataFrame(columns = col_names)\n",
    "    \n",
    "    pbar = tqdm(total=len(df['SessionId'].unique()))\n",
    "    \n",
    "    for row in df.iterrows():\n",
    "        for rep in range(int(row[1]['DwellReps'])):\n",
    "            augmented = augmented.append(row[1])#Df, ignore_index=True)\n",
    "        pbar.update(1)\n",
    "        \n",
    "    pbar.close()\n",
    "            \n",
    "    return augmented\n",
    "\n",
    "def augment(df):    \n",
    "    col_names = list(df.columns.values)[:3]\n",
    "    print(col_names)\n",
    "    augmented = np.repeat(df.values, df['DwellReps'], axis=0) \n",
    "    print(augmented[0][:3])  \n",
    "    augmented = pd.DataFrame(data=augmented[:,:3],\n",
    "                             columns=col_names)\n",
    "    \n",
    "    dtype = {'SessionId': np.int64, \n",
    "             'ItemId': np.int64, \n",
    "             'Time': np.float32}\n",
    "    \n",
    "    for k, v in dtype.items():\n",
    "        augmented[k] = augmented[k].astype(v)\n",
    "                             \n",
    "    \n",
    "    return augmented\n",
    "\n",
    "df_aug = augment(new_df)\n",
    "        \n",
    "print(df_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68052530, 3)\n",
      "    SessionId     ItemId          Time\n",
      "0           1  214536502  1.396879e+09\n",
      "1           1  214536502  1.396879e+09\n",
      "2           1  214536502  1.396879e+09\n",
      "3           1  214536500  1.396879e+09\n",
      "4           1  214536506  1.396879e+09\n",
      "5           1  214536506  1.396879e+09\n",
      "6           1  214577561  1.396879e+09\n",
      "7           2  214662742  1.396890e+09\n",
      "8           2  214662742  1.396890e+09\n",
      "9           2  214662742  1.396890e+09\n",
      "10          2  214825110  1.396890e+09\n",
      "11          2  214757390  1.396890e+09\n",
      "12          2  214757407  1.396890e+09\n",
      "13          2  214757407  1.396890e+09\n",
      "14          2  214551617  1.396890e+09\n",
      "15          3  214716935  1.396455e+09\n",
      "16          3  214716935  1.396455e+09\n",
      "17          3  214716935  1.396455e+09\n",
      "18          3  214716935  1.396455e+09\n",
      "19          3  214716935  1.396455e+09\n"
     ]
    }
   ],
   "source": [
    "print(df_aug.shape)\n",
    "print(df_aug[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_aug.to_pickle(\"./augmented.pkl\")\n",
    "df_aug.to_csv(\"./augmented.csv\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3kJRW-qQ17_Q",
    "outputId": "1e336f48-43aa-4929-cefd-63e02dee3449",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6c11a45640e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhumanize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import math\n",
    "import sklearn\n",
    "import psutil\n",
    "import humanize\n",
    "import GPUtil as GPU\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import cosine_proximity, categorical_crossentropy\n",
    "from keras.models import Model, Sequential\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Input, Dense, Dropout, CuDNNGRU, Embedding, concatenate, Lambda, multiply\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "ik4GlGz8oZvj",
    "outputId": "bc42d34e-ecb5-4666-e44b-e89aea8c82f3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Configuracion GPUs\n",
    "#!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "\n",
    "GPUs = GPU.getGPUs()\n",
    "gpu = GPUs[0]\n",
    "\n",
    "def print_gpu_info():\n",
    "  process = psutil.Process(os.getpid())\n",
    "  print(\"Gen RAM Free: \" + humanize.naturalsize(\n",
    "          psutil.virtual_memory().available), \" I Proc size: \"  +\n",
    "          humanize.naturalsize(process.memory_info().rss))\n",
    "  print(\"GPU RAM Free {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total \\\n",
    "         {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, \n",
    "                           gpu.memoryTotal))\n",
    "  \n",
    "print_gpu_info()\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [(x.name, x.DESCRIPTOR, x.DEVICE_TYPE_FIELD_NUMBER, x.NAME_FIELD_NUMBER, x.PHYSICAL_DEVICE_DESC_FIELD_NUMBER) for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFkivhjnvrKO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(data, batch_size=128, session_max_len=19, fraction=1, offset=0, embedding=True, n_items=None, itemids=None, itemidmap=None, aug = True):\n",
    "    item_key = 'ItemId'\n",
    "    session_key = 'SessionId'\n",
    "    time_key = 'Time'\n",
    "    \n",
    "    data = pd.merge(data, pd.DataFrame({item_key:itemids, 'ItemIdx':itemidmap[itemids].values}), on=item_key, how='inner') # agrego esa columna\n",
    "    \n",
    "    #print(\"Cantidad de samples: {}\".format(len(data)//fraction))\n",
    "\n",
    "    data.sort_values([session_key, time_key], inplace=True) # ordenamos por sesion\n",
    "\n",
    "    #data.sort_values([time_key], inplace=True)\n",
    "    length = len(data['ItemId'])\n",
    "    #data = data[length-length//fraction:]\n",
    "    \n",
    "    offset_sessions = np.zeros(data[session_key].nunique()+1, dtype=np.int32)\n",
    "    offset_sessions[1:] = data.groupby(session_key).size().cumsum() # arreglo con offset acumulativo de inicio de cada sesion\n",
    "    #offset_sessions = offset_sessions[length-length//fraction:]\n",
    "    \n",
    "    actual_session = 0 + offset\n",
    "    \n",
    "    batch_feats = None\n",
    "    batch_labels = None\n",
    "    # GRU_LAYER.reset_states() si usamos session parallel\n",
    "\n",
    "    while True:\n",
    "      datum = data[offset_sessions[actual_session]:offset_sessions[actual_session+1]][item_key]  # aqui toda la info de la sesion\n",
    "      datum = datum.values.reshape(-1,1)           \n",
    "      for i in range(offset_sessions[actual_session+1]-offset_sessions[actual_session]-1):\n",
    "        if not aug:\n",
    "          if (i != offset_sessions[actual_session+1]-offset_sessions[actual_session]-2):\n",
    "            continue\n",
    "        feats = datum[0:i+1]\n",
    "   \n",
    "        if feats.shape[0] > session_max_len:\n",
    "            feats = feats[:session_max_len] # aca cambiar a mas nuevos\n",
    "        else:\n",
    "            feats = np.append(np.zeros((session_max_len-feats.shape[0],1), dtype=np.int8), feats) # left pad with zeros\n",
    "\n",
    "        feats = feats.reshape(1,-1) # (1, 19)\n",
    "\n",
    "        label = datum[i+1]\n",
    "        label = np.expand_dims(label, axis=0)  # Termina siendo (1, dimn_previa)\n",
    "\n",
    "\n",
    "        if not isinstance(batch_feats, type(feats)):\n",
    "            batch_feats = feats\n",
    "        else:\n",
    "            batch_feats = np.append(batch_feats, feats, axis=0)\n",
    "\n",
    "        if not isinstance(batch_labels, type(label)):\n",
    "            batch_labels = label\n",
    "        else:\n",
    "            batch_labels = np.append(batch_labels, label, axis=0)\n",
    "\n",
    "        #print(batch_feats)\n",
    "        #print(batch_labels)\n",
    "        \n",
    "        if batch_labels.shape[0] == batch_size:\n",
    "          if not embedding:\n",
    "            # batch_labels.shape = (batch_size, 1)\n",
    "            #new_labels = np.zeros((batch_size, n_items))\n",
    "            #new_labels[0][:] = to_categorical(itemidmap[label[0][0]], num_classes=n_items)\n",
    "            batch_labels = to_categorical(itemidmap[batch_labels.flatten()], num_classes=n_items)\n",
    "          #print(\"Yielding batch with shape {} train, {} target\".format(batch_feats.shape, batch_labels.shape))\n",
    "            pass\n",
    "          \n",
    "          yield batch_feats, batch_labels\n",
    "          # resume batch generation\n",
    "          batch_feats = None\n",
    "          batch_labels = None\n",
    "\n",
    "    # TODO: Dropout random como en el paper\n",
    "\n",
    "      actual_session = (actual_session + 1) % len(offset_sessions)\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "eQslL5CpRjdQ",
    "outputId": "bd8d7ef2-638d-42a1-eaf5-6e96636a7be7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512 #como en el paper\n",
    "session_max_len = 19\n",
    "embeddingp=False\n",
    "\n",
    "n_items = len(train_data['ItemId'].unique())+1\n",
    "print(\"Items unicos training:\", n_items)\n",
    "\n",
    "dev_n_items = len(dev_data['ItemId'].unique())+1\n",
    "print(\"Items unicos dev:\", dev_n_items)\n",
    "\n",
    "test_n_items = len(test_data['ItemId'].unique())+1\n",
    "print(\"Items unicos testing:\", test_n_items)\n",
    "\n",
    "train_samples_qty = len(train_data['SessionId'].unique()) # cantidad sesiones no augmentadas de train\n",
    "print(\"Sesiones training:\", train_samples_qty)\n",
    "\n",
    "dev_samples_qty = len(dev_data['SessionId'].unique()) # cantidad sesiones no augmentadas de dev\n",
    "print(\"Sesiones validation:\",dev_samples_qty)\n",
    "\n",
    "test_samples_qty = len(test_data['SessionId'].unique()) # cantidad sesiones no augmentadas de test\n",
    "print(\"Sesiones testing:\", test_samples_qty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1i_adI_ASgDi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_fraction = 1#256 # 1/fraction es la cantidad de sesiones mas recientes a considerar\n",
    "dev_fraction = 1#2\n",
    "\n",
    "train_offset_step=35000#40000#15530\n",
    "dev_offset_step=65#240\n",
    "\n",
    "\n",
    "aux = [0]\n",
    "aux.extend(list(train_data['ItemId'].unique()))\n",
    "itemids = np.array(aux)\n",
    "itemidmap = pd.Series(data=np.arange(n_items), index=itemids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5z1JvtX8qV0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_generator = next(batch_generator(test_data, \n",
    "                                batch_size=batch_size, \n",
    "                                fraction=train_fraction, \n",
    "                                offset=3,\n",
    "                               embedding=False,\n",
    "                                n_items=n_items,\n",
    "                               itemids=itemids,\n",
    "                               itemidmap=itemidmap,\n",
    "                                aug = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "O5_sa72xSF50",
    "outputId": "b1a69ec9-6e86-44ba-d19e-69fe1f59cf57",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modelo\n",
    "\n",
    "# ToDo:\n",
    "# meterle self-attention (hay implementaciones en Keras)\n",
    "\n",
    "def custom_cosine_loss(itemidmap, n_items):\n",
    "    #emb = model.layers[1]\n",
    "    emb = itemidmap\n",
    "    nu_items = n_items\n",
    "    # y_pred ya viene con embedding, y_true solo como one-hot\n",
    "    def fn(y_true, y_pred):\n",
    "        #print(y_true.shape, y_pred.shape)\n",
    "        y_pred_emb = to_categorical(emb[y_pred], num_classes=nu_items)\n",
    "        #print(y_true_emb)\n",
    "        #y_pred_emb = emb.call(y_pred)\n",
    "\n",
    "    #y_true_emb = np.array([y_true], dtype='int32')\n",
    "    #y_true_emb = tf.convert_to_tensor(y_true_emb)\n",
    "    #y_true_emb = model.layers[0].call(y_true)\n",
    "    #y_true_emb = K.get_value(y_true_emb)[0][0] # 50,\n",
    "\n",
    "        return 1 - cosine_proximity(y_true, y_pred_emb)\n",
    "        #return cosine_proximity(y_true_emb, y_pred_emb)\n",
    "    return fn\n",
    "    \n",
    "emb_size = 50\n",
    "size = emb_size\n",
    "#size = emb_size if embeddingp else n_items\n",
    "\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "emb = Embedding(n_items, emb_size, embeddings_initializer='uniform', input_length=19)\n",
    "model.add(emb)\n",
    "model.add(Dropout(0.25))\n",
    "model.add(CuDNNGRU(1000)) \n",
    "model.add(Dropout(0.25))\n",
    "if embeddingp:\n",
    "    model.add(Dense(emb_size, activation='softmax'))\n",
    "    custom_loss = custom_cosine_loss(emb)  ## DUDA: Esta usando los pesos actuales?\n",
    "    model.compile(loss=custom_loss, optimizer='adam')\n",
    "else:\n",
    "    model.add(Dense(n_items, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()\n",
    "\"\"\"\n",
    "\n",
    "inputs = Input(shape=(19,))\n",
    "emb = Embedding(n_items, emb_size, embeddings_initializer='uniform', input_length=19)(inputs)\n",
    "drop1 = Dropout(0.25)(emb)\n",
    "gru = CuDNNGRU(1000)(drop1)\n",
    "drop2 = Dropout(0.25)(gru)\n",
    "predictions = Dense(n_items, activation='softmax')(drop2)\n",
    "model = Model(input=inputs, output=[predictions])\n",
    "custom_loss = custom_cosine_loss(itemidmap, n_items)\n",
    "opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "# Try Nadam, too\n",
    "model.compile(loss=categorical_crossentropy, optimizer=opt)\n",
    "model.summary()\n",
    "\n",
    "filepath='./bast/model_checkpoint'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=2, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "1XFQrjF7TZlU",
    "outputId": "9c209770-d67a-4bb3-a0ac-ed2a2a65fc0e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "real_epoca = 1\n",
    "for epoch in range(1):\n",
    "    filepath='./bast/model_{}'.format(real_epoca)\n",
    "    model.load_weights('./bast/model_{}'.format(real_epoca-1))\n",
    "    #model.save_weights(filepath)\n",
    "    train_generator = batch_generator(train_data, \n",
    "                                      batch_size=batch_size, \n",
    "                                      fraction=train_fraction, \n",
    "                                      offset=train_offset_step*epoch,\n",
    "                                     embedding=embeddingp,\n",
    "                                      n_items=n_items,\n",
    "                                     itemids=itemids,\n",
    "                                     itemidmap=itemidmap)\n",
    "    \n",
    "    dev_generator = batch_generator(dev_data, \n",
    "                                    batch_size=batch_size, \n",
    "                                    fraction=dev_fraction, \n",
    "                                    offset=dev_offset_step*epoch,\n",
    "                                    embedding=embeddingp,\n",
    "                                    n_items=n_items,\n",
    "                                    itemids=itemids,\n",
    "                                     itemidmap=itemidmap)\n",
    "    \n",
    "    history = model.fit_generator(train_generator,\n",
    "                                steps_per_epoch=train_offset_step,#15530,\n",
    "                                epochs=1,\n",
    "                                validation_data=dev_generator,\n",
    "                                validation_steps=dev_offset_step,#105,\n",
    "                                callbacks=callbacks_list)\n",
    "    \n",
    "    model.save_weights(filepath)\n",
    "    \n",
    "    weights = model.layers[1].get_weights()[0]\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    nbrs = NearestNeighbors(n_neighbors=20, algorithm='ball_tree').fit(weights)\n",
    "    distances, indices = nbrs.kneighbors(weights) # Vienen ya ordenados! # Shape (37484, 20)\n",
    "    # Paso 3: Dado un vector embedding arbitrario, obtener el item más cercano a éste. Aplicarla sobre los 20 anteriores.\n",
    "    from sklearn.metrics import recall_score\n",
    "\n",
    "    test_generator = batch_generator(test_data, \n",
    "                                      batch_size=batch_size, \n",
    "                                      fraction=train_fraction, \n",
    "                                      offset=0,\n",
    "                                     embedding=embeddingp,\n",
    "                                      n_items=n_items,\n",
    "                                     itemids=itemids,\n",
    "                                     itemidmap=itemidmap)\n",
    "\n",
    "\n",
    "    n = 0\n",
    "    suma = 0\n",
    "    while True:\n",
    "          try:\n",
    "            test_batch = next(test_generator)\n",
    "            pred = model.predict(test_batch[0]) # batch_size, n_items => 512, 37484\n",
    "            label = test_batch[1]               \n",
    "\n",
    "            #print(pred.shape)\n",
    "            #print(label.shape) \n",
    "\n",
    "            for row_idx in range(test_batch[0].shape[0]):\n",
    "              pred_row = pred[row_idx] # 37484, #.reshape(1, -1) # 50,\n",
    "              label_row = label[row_idx]        #.reshape(1, -1) # 50,\n",
    "\n",
    "              #print(pred_row.shape)\n",
    "              #print(label_row.shape)\n",
    "\n",
    "              idx1 = pred_row.argsort()[-20:][::-1]\n",
    "              idx2 = label_row.argsort()[-1:][::-1]\n",
    "\n",
    "              n += 1\n",
    "              #print(idx1)\n",
    "              #print(idx2)\n",
    "              if idx2[0] in idx1:\n",
    "                suma += 1\n",
    "\n",
    "          except:\n",
    "            break\n",
    "    print(\"Recall epoch {}: {}\".format(epoch, suma/n))\n",
    "    real_epoca += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath='./bast/model_{}'.format(epoch)\n",
    "model.save_weights(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Started @ 9.2\n",
    "\n",
    "En 8.01 se puso lento... ojo\n",
    "\n",
    "Goin up 7.8464\n",
    "\n",
    "Epoch time: 2:00 aprox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = model.layers[1].get_weights()[0]\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=20, algorithm='ball_tree').fit(weights)\n",
    "distances, indices = nbrs.kneighbors(weights) # Vienen ya ordenados! # Shape (37484, 20)\n",
    "# Paso 3: Dado un vector embedding arbitrario, obtener el item más cercano a éste. Aplicarla sobre los 20 anteriores.\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "test_generator = batch_generator(test_data, \n",
    "                                  batch_size=batch_size, \n",
    "                                  fraction=train_fraction, \n",
    "                                  offset=0,\n",
    "                                 embedding=embeddingp,\n",
    "                                  n_items=n_items,\n",
    "                                 itemids=itemids,\n",
    "                                 itemidmap=itemidmap)\n",
    "\n",
    "\n",
    "n = 0\n",
    "suma = 0\n",
    "while True:\n",
    "  try:\n",
    "    test_batch = next(test_generator)\n",
    "    pred = model.predict(test_batch[0]) # batch_size, n_items => 512, 37484\n",
    "    label = test_batch[1]               \n",
    "\n",
    "    #print(pred.shape)\n",
    "    #print(label.shape) \n",
    "\n",
    "    for row_idx in range(test_batch[0].shape[0]):\n",
    "      pred_row = pred[row_idx] # 37484, #.reshape(1, -1) # 50,\n",
    "      label_row = label[row_idx]        #.reshape(1, -1) # 50,\n",
    "\n",
    "      #print(pred_row.shape)\n",
    "      #print(label_row.shape)\n",
    "\n",
    "      idx1 = pred_row.argsort()[-20:][::-1]\n",
    "      idx2 = label_row.argsort()[-1:][::-1]\n",
    "\n",
    "      n += 1\n",
    "      #print(idx1)\n",
    "      #print(idx2)\n",
    "      if idx2[0] in idx1:\n",
    "        suma += 1\n",
    "\n",
    "  except:\n",
    "    break\n",
    "print(\"Recall epoch {}: {}\".format(epoch, suma/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall epoch 0: 0.0005554759174311927 # seste se disparo y lo corte\n",
    "\n",
    "Recall epoch 0: 0.009550602064220183 # primera con lr mas bajo\n",
    "Recall epoch 1: 0.009084719036697247\n",
    "\n",
    "# TODO\n",
    "\n",
    "## Batcher solo entrega una sesion a la vez, si no se pierde independencia"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IIC3633_M1_Colab_V2.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
